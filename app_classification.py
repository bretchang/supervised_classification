import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

from sklearn.datasets import (
    load_iris, load_wine, load_breast_cancer, 
    load_digits, make_classification, fetch_20newsgroups
)
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report, roc_auc_score, roc_curve
)
from sklearn.feature_extraction.text import TfidfVectorizer
from imblearn.over_sampling import SMOTE
import warnings
warnings.filterwarnings('ignore')

# è¨­ç½®é é¢é…ç½®
st.set_page_config(
    page_title="ç›£ç£å¼å­¸ç¿’-åˆ†é¡äº’å‹•æ•™å­¸å¹³å°",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šç¾©CSSæ¨£å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .section-header {
        font-size: 1.8rem;
        color: #ff7f0e;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
    .metric-card {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
        margin: 0.5rem 0;
    }
    .small-text {
        font-size: 0.7rem !important;
        line-height: 1.2 !important;
    }
</style>
""", unsafe_allow_html=True)

# å´é‚Šæ¬„å°èˆª
st.sidebar.title("ğŸ¯ èª²ç¨‹å°èˆª")
page = st.sidebar.radio(
    "é¸æ“‡å­¸ç¿’æ¨¡å¡Šï¼š",
    [
        "ğŸ  ç›£ç£å¼å­¸ç¿’æ¦‚è¿°",
        "ğŸ“Š æ•¸æ“šé›†æ¢ç´¢", 
        "ğŸ“ˆ é‚è¼¯å›æ­¸",
        "ğŸ¯ Kè¿‘é„°åˆ†é¡",
        "ğŸŒ³ æ±ºç­–æ¨¹åˆ†é¡",
        "ğŸŒ² éš¨æ©Ÿæ£®æ—åˆ†é¡",
        "ğŸš€ æ¢¯åº¦æå‡åˆ†é¡",
        "ğŸ¯ æ”¯æŒå‘é‡æ©Ÿ",
        "ğŸ§® è²è‘‰æ–¯åˆ†é¡å™¨",
        "ğŸ§  ç¥ç¶“ç¶²è·¯åˆ†é¡",
        "ğŸ“ è©•åƒ¹æŒ‡æ¨™è©³è§£",
        "ğŸ”„ äº¤å‰é©—è­‰èˆ‡ç©©å®šæ€§",
        "âš–ï¸ è³‡æ–™ä¸å¹³è¡¡è™•ç†",
        "ğŸ” æ¨¡å‹å¯è§£é‡‹æ€§",
        "ğŸ† æ¨¡å‹ç¶œåˆæ¯”è¼ƒ"
    ]
)

# æ•¸æ“šé›†é¸æ“‡æ”¾åœ¨å´é‚Šæ¬„
st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ“Š æ•¸æ“šé›†é¸æ“‡")
dataset_choice = st.sidebar.selectbox("é¸æ“‡æ•¸æ“šé›†ï¼š", [
    "é³¶å°¾èŠ±åˆ†é¡", "ç´…é…’åˆ†é¡", "ä¹³ç™Œè¨ºæ–·", "æ‰‹å¯«æ•¸å­—è­˜åˆ¥", "äººå·¥æ•¸æ“šé›†", "æ–°èåˆ†é¡"
])

# æ•¸æ“šé›†ç°¡ä»‹
dataset_info = {
    "é³¶å°¾èŠ±åˆ†é¡": "ğŸŒ¸ ç¶“å…¸3åˆ†é¡å•é¡Œï¼Œé©åˆå…¥é–€å­¸ç¿’ (1KB)",
    "ç´…é…’åˆ†é¡": "ğŸ· ç´…é…’å“ç¨®åˆ†é¡ï¼Œé©åˆç‰¹å¾µå·¥ç¨‹ (13KB)",
    "ä¹³ç™Œè¨ºæ–·": "ğŸ©º äºŒåˆ†é¡é†«å­¸è¨ºæ–·ï¼Œå¯¦éš›æ‡‰ç”¨å ´æ™¯ (32KB)", 
    "æ‰‹å¯«æ•¸å­—è­˜åˆ¥": "ğŸ”¢ 10åˆ†é¡æŒ‘æˆ°ï¼Œåœ–åƒè­˜åˆ¥å…¥é–€ (180KB)",
    "äººå·¥æ•¸æ“šé›†": "ğŸ² å¯æ§åˆ¶è¤‡é›œåº¦ï¼Œæ•™å­¸å¯¦é©—ç”¨ (å¯èª¿)",
    "æ–°èåˆ†é¡": "ğŸ“° æ–‡æœ¬åˆ†é¡ï¼Œè‡ªç„¶èªè¨€è™•ç† (1.2MB)"
}

st.sidebar.markdown("### ğŸ“ æ•¸æ“šé›†ç‰¹é»")
for dataset, description in dataset_info.items():
    if dataset == dataset_choice:
        st.sidebar.markdown(f'<div class="small-text">âœ… <strong>{dataset}</strong>: {description}</div>', unsafe_allow_html=True)
    else:
        st.sidebar.markdown(f'<div class="small-text"><strong>{dataset}</strong>: {description}</div>', unsafe_allow_html=True)

st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ‘¨â€ğŸ’» ä½œè€…ä¿¡æ¯")
st.sidebar.info("**This tutorial was made by CCChang18** ğŸš€")

# åˆå§‹åŒ–session_state
if 'artificial_params' not in st.session_state:
    st.session_state.artificial_params = {
        'n_samples': 1000,
        'n_features': 10,
        'n_informative': 5,
        'n_redundant': 2,
        'n_classes': 3,
        'class_sep': 1.0,
        'random_state': 42
    }

# æ•¸æ“šè¼‰å…¥å‡½æ•¸
@st.cache_data
def load_datasets():
    datasets = {}
    
    # é³¶å°¾èŠ±æ•¸æ“šé›†
    iris = load_iris()
    iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)
    iris_df['target'] = iris.target
    iris_df['target_names'] = [iris.target_names[i] for i in iris.target]
    datasets['é³¶å°¾èŠ±åˆ†é¡'] = iris_df
    
    # ç´…é…’æ•¸æ“šé›†
    wine = load_wine()
    wine_df = pd.DataFrame(wine.data, columns=wine.feature_names)
    wine_df['target'] = wine.target
    wine_df['target_names'] = [wine.target_names[i] for i in wine.target]
    datasets['ç´…é…’åˆ†é¡'] = wine_df
    
    # ä¹³ç™Œè¨ºæ–·æ•¸æ“šé›†
    cancer = load_breast_cancer()
    cancer_df = pd.DataFrame(cancer.data, columns=cancer.feature_names)
    cancer_df['target'] = cancer.target
    cancer_df['target_names'] = [cancer.target_names[i] for i in cancer.target]
    datasets['ä¹³ç™Œè¨ºæ–·'] = cancer_df
    
    # æ‰‹å¯«æ•¸å­—è­˜åˆ¥æ•¸æ“šé›†
    digits = load_digits()
    digits_df = pd.DataFrame(digits.data, columns=[f'pixel_{i}' for i in range(digits.data.shape[1])])
    digits_df['target'] = digits.target
    digits_df['target_names'] = [str(i) for i in digits.target]
    datasets['æ‰‹å¯«æ•¸å­—è­˜åˆ¥'] = digits_df
    
    # äººå·¥æ•¸æ“šé›† - ä½¿ç”¨session_stateä¾†å­˜å„²åƒæ•¸
    params = st.session_state.artificial_params
    X_artificial, y_artificial = make_classification(
        n_samples=params['n_samples'], 
        n_features=params['n_features'], 
        n_informative=params['n_informative'], 
        n_redundant=params['n_redundant'], 
        n_clusters_per_class=1, 
        n_classes=params['n_classes'],
        class_sep=params['class_sep'],
        random_state=params['random_state']
    )
    artificial_df = pd.DataFrame(X_artificial, columns=[f'feature_{i}' for i in range(X_artificial.shape[1])])
    artificial_df['target'] = y_artificial
    artificial_df['target_names'] = [f'Class_{i}' for i in y_artificial]
    datasets['äººå·¥æ•¸æ“šé›†'] = artificial_df
    
    # æ–°èåˆ†é¡æ•¸æ“šé›† (ç°¡åŒ–ç‰ˆ)
    try:
        # åªä½¿ç”¨å°‘æ•¸é¡åˆ¥ä»¥æ¸›å°‘è¤‡é›œåº¦
        categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']
        newsgroups = fetch_20newsgroups(subset='train', categories=categories, 
                                      remove=('headers', 'footers', 'quotes'))
        
        # æ–‡æœ¬å‘é‡åŒ– (ç°¡åŒ–)
        vectorizer = TfidfVectorizer(max_features=100, stop_words='english')
        X_news = vectorizer.fit_transform(newsgroups.data).toarray()
        
        news_df = pd.DataFrame(X_news, columns=[f'word_{i}' for i in range(X_news.shape[1])])
        news_df['target'] = newsgroups.target
        news_df['target_names'] = [newsgroups.target_names[i] for i in newsgroups.target]
        datasets['æ–°èåˆ†é¡'] = news_df
    except:
        # å¦‚æœè¼‰å…¥å¤±æ•—ï¼Œå‰µå»ºå‡æ•¸æ“š
        X_fake, y_fake = make_classification(
            n_samples=500, n_features=20, n_classes=4, random_state=42
        )
        fake_df = pd.DataFrame(X_fake, columns=[f'word_{i}' for i in range(X_fake.shape[1])])
        fake_df['target'] = y_fake
        fake_df['target_names'] = [f'Topic_{i}' for i in y_fake]
        datasets['æ–°èåˆ†é¡'] = fake_df
    
    return datasets

all_datasets = load_datasets()

# é€šç”¨æ•¸æ“šç²å–å‡½æ•¸
def get_current_data():
    try:
        current_dataset = all_datasets[dataset_choice]
        if current_dataset is None or len(current_dataset) == 0:
            st.error(f"âŒ æ•¸æ“šé›† '{dataset_choice}' ç‚ºç©ºæˆ–ç„¡æ³•åŠ è¼‰")
            return pd.DataFrame(), pd.Series(dtype=int), []
        
        X = current_dataset.drop(['target', 'target_names'], axis=1)
        y = current_dataset['target']
        target_names = current_dataset['target_names'].unique()
        
        # ç¢ºä¿æ•¸æ“šé¡å‹æ­£ç¢º
        X = X.select_dtypes(include=[np.number])  # åªé¸æ“‡æ•¸å€¼å‹ç‰¹å¾µ
        
        if len(X.columns) == 0:
            st.error(f"âŒ æ•¸æ“šé›† '{dataset_choice}' æ²’æœ‰æ•¸å€¼å‹ç‰¹å¾µ")
            return pd.DataFrame(), pd.Series(dtype=int), []
            
        # ç§»é™¤ä»»ä½•ç¼ºå¤±å€¼
        mask = ~(X.isnull().any(axis=1) | y.isnull())
        X = X[mask]
        y = y[mask]
        
        if len(X) == 0:
            st.error(f"âŒ æ•¸æ“šé›† '{dataset_choice}' åœ¨ç§»é™¤ç¼ºå¤±å€¼å¾Œç‚ºç©º")
            return pd.DataFrame(), pd.Series(dtype=int), []
        
        return X, y, target_names
        
    except Exception as e:
        st.error(f"âŒ åŠ è¼‰æ•¸æ“šé›† '{dataset_choice}' æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return pd.DataFrame(), pd.Series(dtype=int), []

# é é¢å…§å®¹
if page == "ğŸ  ç›£ç£å¼å­¸ç¿’æ¦‚è¿°":
    st.markdown('<h1 class="main-header">ç›£ç£å¼å­¸ç¿’(Supervised Learning)-åˆ†é¡ äº’å‹•æ•™å­¸å¹³å°</h1>', unsafe_allow_html=True)
    
    st.markdown("## ğŸ¯ ä»€éº¼æ˜¯åˆ†é¡ï¼Ÿ")
    
    st.markdown("""
    **åˆ†é¡(Classification)**æ˜¯ç›£ç£å¼å­¸ç¿’çš„é‡è¦åˆ†æ”¯ï¼Œç›®æ¨™æ˜¯å°‡æ•¸æ“šé»åˆ†é…åˆ°é å®šç¾©çš„é¡åˆ¥ä¸­ï¼š
    
    1. **é›¢æ•£è¼¸å‡º**ï¼šé æ¸¬çµæœæ˜¯æœ‰é™çš„é¡åˆ¥æ¨™ç±¤
    2. **æ±ºç­–é‚Šç•Œ**ï¼šå­¸ç¿’å€åˆ†ä¸åŒé¡åˆ¥çš„é‚Šç•Œ
    3. **æ¦‚ç‡ä¼°è¨ˆ**ï¼šå¤šæ•¸ç®—æ³•å¯æä¾›é¡åˆ¥æ¦‚ç‡
    """)
    
    st.markdown("### ğŸ” åˆ†é¡ vs å›æ­¸")
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        **åˆ†é¡(Classification)**ï¼šé æ¸¬**é›¢æ•£é¡åˆ¥**
        - åƒåœ¾éƒµä»¶åµæ¸¬ (åƒåœ¾/æ­£å¸¸)
        - ç–¾ç—…è¨ºæ–· (æ‚£ç—…/å¥åº·)
        - åœ–åƒè­˜åˆ¥ (è²“/ç‹—/é³¥)
        - æƒ…æ„Ÿåˆ†æ (æ­£é¢/è² é¢/ä¸­æ€§)
        """)
    
    with col2:
        st.markdown("""
        **å›æ­¸(Regression)**ï¼šé æ¸¬**é€£çºŒæ•¸å€¼**
        - æˆ¿åƒ¹é æ¸¬
        - æº«åº¦é æ¸¬  
        - è‚¡åƒ¹é æ¸¬
        - éŠ·å”®é¡é æ¸¬
        """)
    
    st.markdown("### ğŸ“Š åˆ†é¡ç¤ºä¾‹ï¼šæ±ºç­–é‚Šç•Œ")
    
    # å‰µå»ºåˆ†é¡ç¤ºæ„åœ–
    np.random.seed(42)
    n_samples = 100
    
    # ç”Ÿæˆå…©é¡æ•¸æ“š
    class_0_x = np.random.normal(2, 1, n_samples//2)
    class_0_y = np.random.normal(2, 1, n_samples//2)
    class_1_x = np.random.normal(4, 1, n_samples//2)
    class_1_y = np.random.normal(4, 1, n_samples//2)
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=class_0_x, y=class_0_y, mode='markers',
        name='é¡åˆ¥ A', marker=dict(color='blue', size=8)
    ))
    
    fig.add_trace(go.Scatter(
        x=class_1_x, y=class_1_y, mode='markers',
        name='é¡åˆ¥ B', marker=dict(color='red', size=8)
    ))
    
    # æ·»åŠ æ±ºç­–é‚Šç•Œ
    x_line = np.linspace(0, 6, 100)
    y_line = x_line
    fig.add_trace(go.Scatter(
        x=x_line, y=y_line, mode='lines',
        name='æ±ºç­–é‚Šç•Œ', line=dict(color='green', width=3, dash='dash')
    ))
    
    fig.update_layout(
        title="åˆ†é¡ç¤ºä¾‹ï¼šå°‹æ‰¾æ±ºç­–é‚Šç•Œå€åˆ†ä¸åŒé¡åˆ¥",
        xaxis_title="ç‰¹å¾µ 1",
        yaxis_title="ç‰¹å¾µ 2",
        height=400
    )
    st.plotly_chart(fig, use_container_width=True)
    
    st.markdown("## ğŸ“š æœ¬èª²ç¨‹å­¸ç¿’å…§å®¹")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        ### ğŸ”§ æ ¸å¿ƒç®—æ³•
        - é‚è¼¯å›æ­¸
        - Kè¿‘é„°åˆ†é¡
        - æ±ºç­–æ¨¹åˆ†é¡
        - éš¨æ©Ÿæ£®æ—åˆ†é¡
        - æ”¯æŒå‘é‡æ©Ÿ
        - è²è‘‰æ–¯åˆ†é¡å™¨
        - ç¥ç¶“ç¶²è·¯åˆ†é¡
        """)
    
    with col2:
        st.markdown("""
        ### ğŸ“ è©•åƒ¹æŒ‡æ¨™
        - æº–ç¢ºç‡ (Accuracy)
        - ç²¾ç¢ºç‡ (Precision)
        - å¬å›ç‡ (Recall)
        - F1åˆ†æ•¸
        - ROC-AUC
        - æ··æ·†çŸ©é™£
        """)
    
    with col3:
        st.markdown("""
        ### ğŸ”„ ç‰¹æ®Šä¸»é¡Œ
        - å¤šåˆ†é¡å•é¡Œ
        - è³‡æ–™ä¸å¹³è¡¡è™•ç†
        - æ¨¡å‹å¯è§£é‡‹æ€§
        - æ±ºç­–é‚Šç•Œè¦–è¦ºåŒ–
        - ç‰¹å¾µé‡è¦æ€§åˆ†æ
        """)
    
    st.markdown("## ğŸ¯ å­¸ç¿’ç›®æ¨™")
    st.info("""
    é€šéæœ¬èª²ç¨‹ï¼Œæ‚¨å°‡èƒ½å¤ ï¼š
    1. ç†è§£ä¸åŒåˆ†é¡ç®—æ³•çš„åŸç†å’Œé©ç”¨å ´æ™¯
    2. æŒæ¡åˆ†é¡æ¨¡å‹çš„è©•ä¼°æ–¹æ³•
    3. å­¸æœƒè™•ç†å¤šåˆ†é¡å’Œä¸å¹³è¡¡æ•¸æ“šå•é¡Œ
    4. é€²è¡Œæ¨¡å‹æ¯”è¼ƒå’Œé¸æ“‡
    5. æå‡æ¨¡å‹çš„å¯è§£é‡‹æ€§
    """)

elif page == "ğŸ“Š æ•¸æ“šé›†æ¢ç´¢":
    st.markdown('<h1 class="main-header">ğŸ“Š æ•¸æ“šé›†æ¢ç´¢</h1>', unsafe_allow_html=True)
    
    st.info("ğŸ’¡ æ‚¨å¯ä»¥åœ¨å·¦å´é¸æ“‡ä¸åŒçš„æ•¸æ“šé›†ä¾†æ¢ç´¢å…¶ç‰¹æ€§")
    
    # äººå·¥æ•¸æ“šé›†åƒæ•¸æ§åˆ¶ç•Œé¢
    if dataset_choice == "äººå·¥æ•¸æ“šé›†":
        st.markdown("## ğŸ›ï¸ äººå·¥æ•¸æ“šé›†åƒæ•¸æ§åˆ¶")
        st.info("ğŸ’¡ æ‚¨å¯ä»¥èª¿æ•´äººå·¥æ•¸æ“šé›†çš„åƒæ•¸ä¾†å‰µå»ºä¸åŒè¤‡é›œåº¦çš„åˆ†é¡å•é¡Œ")
        
        # åƒæ•¸æ§åˆ¶ç•Œé¢
        col1, col2 = st.columns(2)
        
        # ç²å–ç•¶å‰åƒæ•¸
        current_params = st.session_state.artificial_params
        
        with col1:
            n_samples = st.slider("æ¨£æœ¬æ•¸é‡ï¼š", 100, 2000, current_params['n_samples'], 100)
            n_features = st.slider("ç¸½ç‰¹å¾µæ•¸ï¼š", 5, 20, current_params['n_features'])
            n_informative = st.slider("æœ‰ç”¨ç‰¹å¾µæ•¸ï¼š", 2, n_features, min(current_params['n_informative'], n_features))
        
        with col2:
            n_redundant = st.slider("å†—é¤˜ç‰¹å¾µæ•¸ï¼š", 0, n_features-n_informative, min(current_params['n_redundant'], n_features-n_informative))
            n_classes = st.slider("é¡åˆ¥æ•¸é‡ï¼š", 2, 5, current_params['n_classes'])
            class_sep = st.slider("é¡åˆ¥åˆ†é›¢åº¦ï¼š", 0.1, 3.0, current_params['class_sep'], 0.1)
        
        random_state = st.slider("éš¨æ©Ÿç¨®å­ï¼š", 1, 100, current_params['random_state'])
        
        # æ›´æ–°æŒ‰éˆ•
        if st.button("ğŸ”„ æ›´æ–°æ•¸æ“šé›†", type="primary"):
            st.session_state.artificial_params = {
                'n_samples': n_samples,
                'n_features': n_features,
                'n_informative': n_informative,
                'n_redundant': n_redundant,
                'n_classes': n_classes,
                'class_sep': class_sep,
                'random_state': random_state
            }
            st.cache_data.clear()  # æ¸…é™¤ç·©å­˜ä»¥é‡æ–°ç”Ÿæˆæ•¸æ“š
            st.rerun()
        
        # é¡¯ç¤ºç•¶å‰åƒæ•¸
        st.markdown("### ğŸ“‹ ç•¶å‰åƒæ•¸é…ç½®")
        params_info = f"""
        - **æ¨£æœ¬æ•¸é‡**: {current_params['n_samples']}
        - **ç¸½ç‰¹å¾µæ•¸**: {current_params['n_features']}
        - **æœ‰ç”¨ç‰¹å¾µæ•¸**: {current_params['n_informative']}
        - **å†—é¤˜ç‰¹å¾µæ•¸**: {current_params['n_redundant']}
        - **é¡åˆ¥æ•¸é‡**: {current_params['n_classes']}
        - **é¡åˆ¥åˆ†é›¢åº¦**: {current_params['class_sep']}
        """
        st.info(params_info)
    
    # ç²å–ç•¶å‰é¸æ“‡çš„æ•¸æ“šé›†
    current_dataset = all_datasets[dataset_choice]
    
    # æ•¸æ“šé›†ä¿¡æ¯æ˜ å°„ - å‹•æ…‹ç”Ÿæˆäººå·¥æ•¸æ“šé›†ä¿¡æ¯
    artificial_params = st.session_state.artificial_params
    dataset_descriptions = {
        "é³¶å°¾èŠ±åˆ†é¡": {
            "title": "ğŸŒ¸ é³¶å°¾èŠ±å“ç¨®åˆ†é¡æ•¸æ“šé›†",
            "target_desc": "é³¶å°¾èŠ±å“ç¨® (setosa, versicolor, virginica)",
            "source": "ç¶“å…¸æ©Ÿå™¨å­¸ç¿’æ•¸æ“šé›†",
            "features": {
                "sepal length": "èŠ±è¼é•·åº¦", "sepal width": "èŠ±è¼å¯¬åº¦", 
                "petal length": "èŠ±ç“£é•·åº¦", "petal width": "èŠ±ç“£å¯¬åº¦"
            },
            "color": "lightblue",
            "n_classes": 3
        },
        "ç´…é…’åˆ†é¡": {
            "title": "ğŸ· ç´…é…’å“ç¨®åˆ†é¡æ•¸æ“šé›†", 
            "target_desc": "ç´…é…’å“ç¨®é¡åˆ¥ (0, 1, 2)",
            "source": "UCIæ©Ÿå™¨å­¸ç¿’åº«",
            "features": {
                "alcohol": "é…’ç²¾åº¦", "malic_acid": "è˜‹æœé…¸", 
                "ash": "ç°åˆ†", "total_phenols": "ç¸½é…šé¡"
            },
            "color": "lightcoral",
            "n_classes": 3
        },
        "ä¹³ç™Œè¨ºæ–·": {
            "title": "ğŸ©º ä¹³ç™Œè¨ºæ–·æ•¸æ“šé›†",
            "target_desc": "è¨ºæ–·çµæœ (è‰¯æ€§/æƒ¡æ€§)",
            "source": "å¨æ–¯åº·è¾›å¤§å­¸é†«é™¢",
            "features": {
                "mean radius": "å¹³å‡åŠå¾‘", "mean texture": "å¹³å‡ç´‹ç†", 
                "mean perimeter": "å¹³å‡å‘¨é•·", "mean area": "å¹³å‡é¢ç©"
            },
            "color": "lightseagreen",
            "n_classes": 2
        },
        "æ‰‹å¯«æ•¸å­—è­˜åˆ¥": {
            "title": "ğŸ”¢ æ‰‹å¯«æ•¸å­—è­˜åˆ¥æ•¸æ“šé›†",
            "target_desc": "æ•¸å­—é¡åˆ¥ (0-9)",
            "source": "scikit-learnå…§å»ºæ•¸æ“šé›†",
            "features": {
                "pixel_0": "åƒç´ 0", "pixel_1": "åƒç´ 1", 
                "pixel_n": "åƒç´ n", "...": "å…±64å€‹åƒç´ ç‰¹å¾µ"
            },
            "color": "lightgoldenrodyellow",
            "n_classes": 10
        },
        "äººå·¥æ•¸æ“šé›†": {
            "title": "ğŸ² äººå·¥ç”Ÿæˆåˆ†é¡æ•¸æ“šé›†",
            "target_desc": f"äººå·¥é¡åˆ¥ (Class_0 åˆ° Class_{artificial_params['n_classes']-1})",
            "source": "sklearn.make_classificationç”Ÿæˆ",
            "features": {
                "feature_0": "ç‰¹å¾µ0", "feature_1": "ç‰¹å¾µ1", 
                "feature_n": "ç‰¹å¾µn", "...": f"å…±{artificial_params['n_features']}å€‹ç‰¹å¾µ"
            },
            "color": "lightpink",
            "n_classes": artificial_params['n_classes']
        },
        "æ–°èåˆ†é¡": {
            "title": "ğŸ“° æ–°èä¸»é¡Œåˆ†é¡æ•¸æ“šé›†",
            "target_desc": "æ–°èä¸»é¡Œé¡åˆ¥",
            "source": "20newsgroupsæ•¸æ“šé›†",
            "features": {
                "word_0": "è©å½™0", "word_1": "è©å½™1", 
                "word_n": "è©å½™n", "...": "TF-IDFç‰¹å¾µ"
            },
            "color": "lightgreen",
            "n_classes": 4
        }
    }
    
    desc = dataset_descriptions[dataset_choice]
    st.markdown(f"## {desc['title']}")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("### ğŸ“‹ æ•¸æ“šé›†è³‡è¨Š")
        st.info(f"""
        - **æ¨£æœ¬æ•¸é‡**: {len(current_dataset)} å€‹æ¨£æœ¬
        - **ç‰¹å¾µæ•¸é‡**: {len(current_dataset.columns)-2} å€‹ç‰¹å¾µ
        - **é¡åˆ¥æ•¸é‡**: {desc['n_classes']} å€‹é¡åˆ¥
        - **ç›®æ¨™è®Šæ•¸**: {desc['target_desc']}
        - **æ•¸æ“šä¾†æº**: {desc['source']}
        """)
    
    with col2:
        st.markdown("### ğŸ”¬ ä¸»è¦ç‰¹å¾µèªªæ˜")
        for feature, description in desc['features'].items():
            st.markdown(f"- **{feature}**: {description}")
    
    # é¡åˆ¥åˆ†å¸ƒ
    st.markdown("### ğŸ“Š é¡åˆ¥åˆ†å¸ƒ")
    class_counts = current_dataset['target'].value_counts().sort_index()
    class_names = current_dataset['target_names'].unique()
    
    fig = go.Figure(data=[
        go.Bar(x=class_names, y=class_counts.values, marker_color=desc['color'])
    ])
    fig.update_layout(
        title="å„é¡åˆ¥æ¨£æœ¬æ•¸é‡åˆ†å¸ƒ",
        xaxis_title="é¡åˆ¥",
        yaxis_title="æ¨£æœ¬æ•¸é‡",
        height=400
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # æª¢æŸ¥é¡åˆ¥å¹³è¡¡æ€§
    balance_ratio = class_counts.min() / class_counts.max()
    if balance_ratio < 0.5:
        st.warning(f"âš ï¸ æ•¸æ“šä¸å¹³è¡¡ï¼æœ€å°é¡åˆ¥èˆ‡æœ€å¤§é¡åˆ¥æ¯”ä¾‹ï¼š{balance_ratio:.2f}")
    else:
        st.success(f"âœ… æ•¸æ“šç›¸å°å¹³è¡¡ï¼Œé¡åˆ¥æ¯”ä¾‹ï¼š{balance_ratio:.2f}")
    
    # ç‰¹å¾µåˆ†å¸ƒå¯è¦–åŒ–
    st.markdown("### ğŸ“ˆ ç‰¹å¾µåˆ†å¸ƒåˆ†æ")
    
    X, y, target_names = get_current_data()
    if len(X) > 0:
        # é¸æ“‡å‰4å€‹ç‰¹å¾µé€²è¡Œå¯è¦–åŒ–
        features_to_plot = X.columns[:4]
        
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=[f"{col}" for col in features_to_plot]
        )
        
        colors = ['blue', 'red', 'green', 'purple', 'orange', 'brown', 'pink', 'gray', 'olive', 'cyan']
        
        for i, feature in enumerate(features_to_plot):
            row = i // 2 + 1
            col = i % 2 + 1
            
            for class_idx, class_name in enumerate(target_names):
                class_data = X[y == class_idx][feature]
                fig.add_trace(
                    go.Histogram(
                        x=class_data, name=f'{class_name}', 
                        opacity=0.7, nbinsx=20,
                        marker_color=colors[class_idx % len(colors)],
                        showlegend=(i==0)  # åªåœ¨ç¬¬ä¸€å€‹å­åœ–é¡¯ç¤ºåœ–ä¾‹
                    ),
                    row=row, col=col
                )
        
        fig.update_layout(
            title="å„é¡åˆ¥åœ¨ä¸åŒç‰¹å¾µä¸Šçš„åˆ†å¸ƒ",
            height=600
        )
        st.plotly_chart(fig, use_container_width=True)

elif page == "ğŸ“ˆ é‚è¼¯å›æ­¸":
    st.markdown('<h1 class="main-header">ğŸ“ˆ é‚è¼¯å›æ­¸ (Logistic Regression)</h1>', unsafe_allow_html=True)
    
    st.markdown("## ğŸ§® æ•¸å­¸åŸç†")
    
    st.markdown("### ğŸ“ é‚è¼¯å›æ­¸å…¬å¼")
    st.markdown("é‚è¼¯å›æ­¸ä½¿ç”¨Sigmoidå‡½æ•¸å°‡ç·šæ€§å‡½æ•¸çš„è¼¸å‡ºæ˜ å°„åˆ°0-1ä¹‹é–“ï¼š")
    
    st.latex(r'''
    P(y=1|x) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_n x_n)}}
    ''')
    
    st.markdown("### ğŸ¯ Sigmoidå‡½æ•¸")
    st.latex(r'''
    \sigma(z) = \frac{1}{1 + e^{-z}}
    ''')
    
    st.markdown("### ğŸ“Š å°æ•¸æå¤±å‡½æ•¸")
    st.latex(r'''
    J(\beta) = -\frac{1}{m} \sum_{i=1}^{m} [y_i \log(h_\beta(x_i)) + (1-y_i) \log(1-h_\beta(x_i))]
    ''')
    
    # å„ªç¼ºé»
    col1, col2 = st.columns(2)
    
    with col1:
        st.success("### âœ… å„ªé»")
        st.markdown("""
        - ğŸ“Š **æä¾›æ¦‚ç‡è¼¸å‡º**ï¼šä¸åªæ˜¯åˆ†é¡ï¼Œé‚„æœ‰æ¦‚ç‡
        - ğŸ”§ **ç°¡å–®é«˜æ•ˆ**ï¼šè¨ˆç®—æˆæœ¬ä½
        - ğŸ¯ **å¯è§£é‡‹æ€§å¼·**ï¼šä¿‚æ•¸æœ‰æ˜ç¢ºå«ç¾©
        - ğŸ“ˆ **ç„¡éœ€ç‰¹å¾µç¸®æ”¾**ï¼šå°ç‰¹å¾µç¯„åœä¸æ•æ„Ÿ
        - ğŸ›¡ï¸ **ä¸å‡è¨­æ•¸æ“šåˆ†å¸ƒ**ï¼šéåƒæ•¸æ–¹æ³•
        """)
    
    with col2:
        st.error("### âŒ ç¼ºé»")
        st.markdown("""
        - ğŸ“ **å‡è¨­ç·šæ€§é—œä¿‚**ï¼šæ±ºç­–é‚Šç•Œç‚ºç·šæ€§
        - ğŸ¯ **å°é›¢ç¾¤å€¼æ•æ„Ÿ**ï¼šæ¥µå€¼å½±éŸ¿è¼ƒå¤§
        - ğŸ”— **å¤šé‡å…±ç·šæ€§å•é¡Œ**ï¼šç‰¹å¾µç›¸é—œæ€§é«˜æ™‚ä¸ç©©å®š
        - ğŸ“Š **éœ€è¦å¤§æ¨£æœ¬**ï¼šå°æ¨£æœ¬æ™‚ä¸ç©©å®š
        """)
    
    st.markdown("## ğŸ›ï¸ äº’å‹•å¼å¯¦é©—")
    
    X, y, target_names = get_current_data()
    
    if len(X) > 0:
        # åƒæ•¸è¨­ç½®
        col1, col2 = st.columns(2)
        
        with col1:
            solver = st.selectbox("æ±‚è§£å™¨ï¼š", ["liblinear", "lbfgs", "newton-cg", "sag"])
            max_iter = st.slider("æœ€å¤§è¿­ä»£æ¬¡æ•¸ï¼š", 100, 2000, 1000, 100)
        
        with col2:
            test_size = st.slider("æ¸¬è©¦é›†æ¯”ä¾‹ï¼š", 0.1, 0.5, 0.2, 0.05)
            random_seed = st.slider("éš¨æ©Ÿç¨®å­ï¼š", 1, 100, 42)
        
        # ç‰¹å¾µé¸æ“‡
        selected_features = st.multiselect(
            "é¸æ“‡ç”¨æ–¼å»ºæ¨¡çš„ç‰¹å¾µï¼š",
            X.columns.tolist(),
            default=X.columns.tolist()[:4]
        )
        
        if len(selected_features) > 0:
            X_selected = X[selected_features]
            
            # æ•¸æ“šåˆ†å‰²
            X_train, X_test, y_train, y_test = train_test_split(
                X_selected, y, test_size=test_size, random_state=random_seed
            )
            
            # æ¨™æº–åŒ–
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # å»ºç«‹æ¨¡å‹
            model = LogisticRegression(
                solver=solver, max_iter=max_iter, random_state=random_seed
            )
            model.fit(X_train_scaled, y_train)
            
            # é æ¸¬
            y_train_pred = model.predict(X_train_scaled)
            y_test_pred = model.predict(X_test_scaled)
            y_train_proba = model.predict_proba(X_train_scaled)
            y_test_proba = model.predict_proba(X_test_scaled)
            
            # è©•ä¼°æŒ‡æ¨™
            train_acc = accuracy_score(y_train, y_train_pred)
            test_acc = accuracy_score(y_test, y_test_pred)
            
            # è¨ˆç®—å…¶ä»–æŒ‡æ¨™
            if len(target_names) == 2:  # äºŒåˆ†é¡
                train_precision = precision_score(y_train, y_train_pred)
                test_precision = precision_score(y_test, y_test_pred)
                train_recall = recall_score(y_train, y_train_pred)
                test_recall = recall_score(y_test, y_test_pred)
                train_f1 = f1_score(y_train, y_train_pred)
                test_f1 = f1_score(y_test, y_test_pred)
            else:  # å¤šåˆ†é¡
                train_precision = precision_score(y_train, y_train_pred, average='weighted')
                test_precision = precision_score(y_test, y_test_pred, average='weighted')
                train_recall = recall_score(y_train, y_train_pred, average='weighted')
                test_recall = recall_score(y_test, y_test_pred, average='weighted')
                train_f1 = f1_score(y_train, y_train_pred, average='weighted')
                test_f1 = f1_score(y_test, y_test_pred, average='weighted')
            
            # é¡¯ç¤ºçµæœ
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Train-Data æº–ç¢ºç‡", f"{train_acc:.4f}")
            with col2:
                st.metric("Test-Data æº–ç¢ºç‡", f"{test_acc:.4f}")
            with col3:
                st.metric("Train-Data F1", f"{train_f1:.4f}")
            with col4:
                st.metric("Test-Data F1", f"{test_f1:.4f}")
            
            # æ··æ·†çŸ©é™£
            st.markdown("### ğŸ“Š æ··æ·†çŸ©é™£")
            
            col1, col2 = st.columns(2)
            
            with col1:
                cm_train = confusion_matrix(y_train, y_train_pred)
                fig = px.imshow(cm_train, 
                               text_auto=True, 
                               x=target_names, 
                               y=target_names,
                               title="Training Data æ··æ·†çŸ©é™£")
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                cm_test = confusion_matrix(y_test, y_test_pred)
                fig = px.imshow(cm_test, 
                               text_auto=True, 
                               x=target_names, 
                               y=target_names,
                               title="Test Data æ··æ·†çŸ©é™£")
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
            
            # ç‰¹å¾µä¿‚æ•¸åˆ†æ
            st.markdown("### ğŸ“Š ç‰¹å¾µä¿‚æ•¸åˆ†æ")
            
            if len(target_names) == 2:  # äºŒåˆ†é¡
                coef_df = pd.DataFrame({
                    'ç‰¹å¾µ': selected_features,
                    'ä¿‚æ•¸': model.coef_[0],
                    'çµ•å°å€¼': np.abs(model.coef_[0])
                }).sort_values('çµ•å°å€¼', ascending=False)
                
                fig = go.Figure(data=[
                    go.Bar(x=coef_df['ç‰¹å¾µ'], y=coef_df['ä¿‚æ•¸'],
                           marker_color=['red' if x < 0 else 'blue' for x in coef_df['ä¿‚æ•¸']])
                ])
                fig.update_layout(
                    title="é‚è¼¯å›æ­¸ç‰¹å¾µä¿‚æ•¸",
                    xaxis_title="ç‰¹å¾µ",
                    yaxis_title="ä¿‚æ•¸å€¼",
                    xaxis_tickangle=45
                )
                st.plotly_chart(fig, use_container_width=True)
            else:  # å¤šåˆ†é¡
                st.info("å¤šåˆ†é¡å•é¡Œï¼šæ¯å€‹é¡åˆ¥éƒ½æœ‰ä¸€çµ„ä¿‚æ•¸")

elif page == "ğŸ¯ Kè¿‘é„°åˆ†é¡":
    st.markdown('<h1 class="main-header">ğŸ¯ Kè¿‘é„°åˆ†é¡ (K-Nearest Neighbors)</h1>', unsafe_allow_html=True)
    
    st.markdown("## ğŸ§® æ•¸å­¸åŸç†")
    
    st.markdown("### ğŸ“ åŸºæœ¬æ€æƒ³")
    st.markdown("KNNåŸºæ–¼ã€Œç›¸ä¼¼çš„æ¨£æœ¬æ‡‰è©²æœ‰ç›¸ä¼¼çš„æ¨™ç±¤ã€çš„å‡è¨­ï¼š")
    
    st.latex(r'''
    \hat{y} = \text{mode}(\{y_i : x_i \in N_k(x)\})
    ''')
    
    st.markdown("å…¶ä¸­ $N_k(x)$ æ˜¯è·é›¢æŸ¥è©¢é» $x$ æœ€è¿‘çš„ $k$ å€‹é„°å±…ã€‚")
    
    st.markdown("### ğŸ“ è·é›¢åº¦é‡")
    st.markdown("å¸¸ç”¨è·é›¢åº¦é‡ï¼š")
    st.latex(r'''
    \begin{align}
    \text{æ­æ°è·é›¢ï¼š} d(x, y) &= \sqrt{\sum_{i=1}^{n}(x_i - y_i)^2} \\
    \text{æ›¼å“ˆé “è·é›¢ï¼š} d(x, y) &= \sum_{i=1}^{n}|x_i - y_i| \\
    \text{é–”å¯å¤«æ–¯åŸºè·é›¢ï¼š} d(x, y) &= (\sum_{i=1}^{n}|x_i - y_i|^p)^{1/p}
    \end{align}
    ''')
    
    # å„ªç¼ºé»
    col1, col2 = st.columns(2)
    
    with col1:
        st.success("### âœ… å„ªé»")
        st.markdown("""
        - ğŸ¯ **ç°¡å–®ç›´è§€**ï¼šæ˜“æ–¼ç†è§£å’Œå¯¦ç¾
        - ğŸŒŠ **éåƒæ•¸æ–¹æ³•**ï¼šä¸å‡è¨­æ•¸æ“šåˆ†å¸ƒ
        - ğŸ“Š **å¯è™•ç†å¤šåˆ†é¡**ï¼šå¤©ç„¶æ”¯æŒå¤šé¡åˆ¥
        - ğŸ”„ **é©æ‡‰æ€§å¼·**ï¼šèƒ½é©æ‡‰å±€éƒ¨æ•¸æ“šæ¨¡å¼
        - ğŸ› ï¸ **ç„¡éœ€è¨“ç·´**ï¼šæ‡¶æƒ°å­¸ç¿’ç®—æ³•
        """)
    
    with col2:
        st.error("### âŒ ç¼ºé»")
        st.markdown("""
        - â±ï¸ **é æ¸¬é€Ÿåº¦æ…¢**ï¼šéœ€è¦è¨ˆç®—æ‰€æœ‰è·é›¢
        - ğŸ’¿ **è¨˜æ†¶é«”éœ€æ±‚å¤§**ï¼šéœ€è¦å­˜å„²æ‰€æœ‰è¨“ç·´æ•¸æ“š
        - ğŸ“ **å°ç‰¹å¾µç¸®æ”¾æ•æ„Ÿ**ï¼šä¸åŒå°ºåº¦å½±éŸ¿è·é›¢
        - ğŸ¯ **å°å™ªè²å’Œé›¢ç¾¤å€¼æ•æ„Ÿ**ï¼šè¿‘é„°å¯èƒ½æ˜¯å™ªè²
        - ğŸ“ˆ **ç¶­åº¦è©›å’’**ï¼šé«˜ç¶­åº¦æ™‚æ€§èƒ½ä¸‹é™
        """)
    
    st.markdown("## ğŸ›ï¸ äº’å‹•å¼å¯¦é©—")
    
    X, y, target_names = get_current_data()
    
    if len(X) > 0:
        # åƒæ•¸è¨­ç½®
        col1, col2 = st.columns(2)
        
        with col1:
            n_neighbors = st.slider("é„°å±…æ•¸é‡ (k)ï¼š", 1, 20, 5)
            weights = st.selectbox("æ¬Šé‡æ–¹å¼ï¼š", ["uniform", "distance"])
        
        with col2:
            metric = st.selectbox("è·é›¢åº¦é‡ï¼š", ["euclidean", "manhattan", "minkowski"])
            test_size = st.slider("æ¸¬è©¦é›†æ¯”ä¾‹ï¼š", 0.1, 0.5, 0.2, 0.05)
        
        # ç‰¹å¾µé¸æ“‡
        selected_features = st.multiselect(
            "é¸æ“‡ç”¨æ–¼å»ºæ¨¡çš„ç‰¹å¾µï¼š",
            X.columns.tolist(),
            default=X.columns.tolist()[:4]
        )
        
        if len(selected_features) > 0:
            X_selected = X[selected_features]
            
            # æ•¸æ“šåˆ†å‰²
            X_train, X_test, y_train, y_test = train_test_split(
                X_selected, y, test_size=test_size, random_state=42
            )
            
            # æ¨™æº–åŒ–ï¼ˆKNNå¿…é ˆæ¨™æº–åŒ–ï¼‰
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # å»ºç«‹æ¨¡å‹
            model = KNeighborsClassifier(
                n_neighbors=n_neighbors,
                weights=weights,
                metric=metric
            )
            model.fit(X_train_scaled, y_train)
            
            # é æ¸¬
            y_train_pred = model.predict(X_train_scaled)
            y_test_pred = model.predict(X_test_scaled)
            
            # è©•ä¼°æŒ‡æ¨™
            train_acc = accuracy_score(y_train, y_train_pred)
            test_acc = accuracy_score(y_test, y_test_pred)
            
            # è¨ˆç®—å…¶ä»–æŒ‡æ¨™
            if len(target_names) == 2:  # äºŒåˆ†é¡
                train_f1 = f1_score(y_train, y_train_pred)
                test_f1 = f1_score(y_test, y_test_pred)
            else:  # å¤šåˆ†é¡
                train_f1 = f1_score(y_train, y_train_pred, average='weighted')
                test_f1 = f1_score(y_test, y_test_pred, average='weighted')
            
            # é¡¯ç¤ºçµæœ
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Train-Data æº–ç¢ºç‡", f"{train_acc:.4f}")
            with col2:
                st.metric("Test-Data æº–ç¢ºç‡", f"{test_acc:.4f}")
            with col3:
                st.metric("Train-Data F1", f"{train_f1:.4f}")
            with col4:
                st.metric("Test-Data F1", f"{test_f1:.4f}")
            
            # éæ“¬åˆæª¢æ¸¬
            overfitting_gap = train_acc - test_acc
            if overfitting_gap > 0.1:
                st.warning(f"âš ï¸ å¯èƒ½éæ“¬åˆï¼æº–ç¢ºç‡å·®è·ï¼š{overfitting_gap:.4f}")
                st.markdown("**å»ºè­°ï¼š** å¢åŠ kå€¼æˆ–ä½¿ç”¨è·é›¢æ¬Šé‡")
            elif overfitting_gap < -0.05:
                st.info("â„¹ï¸ æ¨¡å‹å¯èƒ½æ¬ æ“¬åˆï¼Œå¯ä»¥æ¸›å°‘kå€¼")
            else:
                st.success("âœ… æ¨¡å‹è¡¨ç¾è‰¯å¥½ï¼")
            
            # æ··æ·†çŸ©é™£
            st.markdown("### ğŸ“Š æ··æ·†çŸ©é™£")
            
            col1, col2 = st.columns(2)
            
            with col1:
                cm_train = confusion_matrix(y_train, y_train_pred)
                fig = px.imshow(cm_train, 
                               text_auto=True, 
                               x=target_names, 
                               y=target_names,
                               title="Training Data æ··æ·†çŸ©é™£")
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                cm_test = confusion_matrix(y_test, y_test_pred)
                fig = px.imshow(cm_test, 
                               text_auto=True, 
                               x=target_names, 
                               y=target_names,
                               title="Test Data æ··æ·†çŸ©é™£")
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
            
            # Kå€¼å½±éŸ¿åˆ†æ
            st.markdown("### ğŸ“ˆ Kå€¼å½±éŸ¿åˆ†æ")
            
            k_range = range(1, min(21, len(X_train)))
            train_scores = []
            test_scores = []
            
            for k in k_range:
                knn = KNeighborsClassifier(n_neighbors=k, weights=weights, metric=metric)
                knn.fit(X_train_scaled, y_train)
                train_scores.append(knn.score(X_train_scaled, y_train))
                test_scores.append(knn.score(X_test_scaled, y_test))
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=list(k_range), y=train_scores, mode='lines+markers', name='Training Accuracy'))
            fig.add_trace(go.Scatter(x=list(k_range), y=test_scores, mode='lines+markers', name='Test Accuracy'))
            fig.update_layout(
                title="ä¸åŒKå€¼å°æ¨¡å‹æ€§èƒ½çš„å½±éŸ¿",
                xaxis_title="Kå€¼",
                yaxis_title="æº–ç¢ºç‡",
                height=400
            )
            st.plotly_chart(fig, use_container_width=True)

elif page == "ğŸŒ³ æ±ºç­–æ¨¹åˆ†é¡":
    st.markdown('<h1 class="main-header">ğŸŒ³ æ±ºç­–æ¨¹åˆ†é¡ (Decision Tree Classification)</h1>', unsafe_allow_html=True)
    
    st.markdown("## ğŸ§® æ•¸å­¸åŸç†")
    
    st.markdown("### ğŸŒ³ æ±ºç­–æ¨¹çš„åŸºæœ¬æ¦‚å¿µ")
    st.markdown("æ±ºç­–æ¨¹é€šéä¸€ç³»åˆ—if-elseè¦å‰‡ä¾†é€²è¡Œåˆ†é¡ï¼š")
    
    st.latex(r'''
    \hat{y} = \text{æ±ºç­–è·¯å¾‘}(x_1, x_2, ..., x_n)
    ''')
    
    st.markdown("### ğŸ“Š ä¸ç´”åº¦åº¦é‡")
    st.markdown("å¸¸ç”¨çš„ä¸ç´”åº¦åº¦é‡ï¼š")
    
    st.latex(r'''
    \begin{align}
    \text{åŸºå°¼ä¸ç´”åº¦ï¼š} Gini(t) &= 1 - \sum_{i=1}^{c} p_i^2 \\
    \text{ä¿¡æ¯ç†µï¼š} Entropy(t) &= -\sum_{i=1}^{c} p_i \log_2(p_i) \\
    \text{åˆ†é¡éŒ¯èª¤ç‡ï¼š} Error(t) &= 1 - \max_i(p_i)
    \end{align}
    ''')
    
    st.markdown("### ğŸ¯ ä¿¡æ¯å¢ç›Š")
    st.latex(r'''
    IG(T, A) = Entropy(T) - \sum_{v \in values(A)} \frac{|T_v|}{|T|} Entropy(T_v)
    ''')
    
    # å„ªç¼ºé»
    col1, col2 = st.columns(2)
    
    with col1:
        st.success("### âœ… å„ªé»")
        st.markdown("""
        - ğŸ“ **æ˜“æ–¼ç†è§£å’Œè§£é‡‹**ï¼šæ¨¹ç‹€çµæ§‹ç›´è§€
        - ğŸ”§ **ä¸éœ€è¦ç‰¹å¾µæ¨™æº–åŒ–**ï¼šè™•ç†åŸå§‹æ•¸æ“š
        - ğŸŒŠ **èƒ½è™•ç†éç·šæ€§é—œä¿‚**ï¼šè¤‡é›œæ±ºç­–é‚Šç•Œ
        - ğŸ¯ **è‡ªå‹•é€²è¡Œç‰¹å¾µé¸æ“‡**ï¼šå¿½ç•¥ä¸é‡è¦ç‰¹å¾µ
        - ğŸ“Š **èƒ½è™•ç†æ•¸å€¼å’Œé¡åˆ¥ç‰¹å¾µ**ï¼šæ··åˆæ•¸æ“šé¡å‹
        - ğŸ›¡ï¸ **å°é›¢ç¾¤å€¼ä¸æ•æ„Ÿ**ï¼šåŸºæ–¼åˆ†å‰²è¦å‰‡
        """)
    
    with col2:
        st.error("### âŒ ç¼ºé»")
        st.markdown("""
        - âš ï¸ **å®¹æ˜“éæ“¬åˆ**ï¼šæ·±åº¦éå¤§æ™‚
        - ğŸ² **å°è¨“ç·´æ•¸æ“šæ•æ„Ÿ**ï¼šå°è®ŠåŒ–å¤§å½±éŸ¿
        - ğŸ“ˆ **åå‘å¤šå€¼ç‰¹å¾µ**ï¼šé¸æ“‡åå·®
        - ğŸ“ **é›£ä»¥æ•æ‰ç·šæ€§é—œä¿‚**ï¼šéœ€è¦å¤šæ¬¡åˆ†å‰²
        - ğŸ”„ **é æ¸¬ä¸ç©©å®š**ï¼šé«˜æ–¹å·®å•é¡Œ
        """)
    
    st.markdown("## ğŸ›ï¸ äº’å‹•å¼å¯¦é©—")
    
    X, y, target_names = get_current_data()
    
    if len(X) > 0:
        # åƒæ•¸è¨­ç½®
        col1, col2 = st.columns(2)
        
        with col1:
            criterion = st.selectbox("åˆ†å‰²æ¨™æº–ï¼š", ["gini", "entropy"])
            max_depth = st.slider("æœ€å¤§æ·±åº¦ï¼š", 1, 20, 5)
        
        with col2:
            min_samples_split = st.slider("æœ€å°åˆ†å‰²æ¨£æœ¬æ•¸ï¼š", 2, 20, 2)
            min_samples_leaf = st.slider("è‘‰ç¯€é»æœ€å°æ¨£æœ¬æ•¸ï¼š", 1, 10, 1)
        
        # ç‰¹å¾µé¸æ“‡
        selected_features = st.multiselect(
            "é¸æ“‡ç”¨æ–¼å»ºæ¨¡çš„ç‰¹å¾µï¼š",
            X.columns.tolist(),
            default=X.columns.tolist()[:4]
        )
        
        if len(selected_features) > 0:
            X_selected = X[selected_features]
            
            # æ•¸æ“šåˆ†å‰²
            X_train, X_test, y_train, y_test = train_test_split(
                X_selected, y, test_size=0.2, random_state=42
            )
            
            # å»ºç«‹æ¨¡å‹
            model = DecisionTreeClassifier(
                criterion=criterion,
                max_depth=max_depth,
                min_samples_split=min_samples_split,
                min_samples_leaf=min_samples_leaf,
                random_state=42
            )
            model.fit(X_train, y_train)
            
            # é æ¸¬
            y_train_pred = model.predict(X_train)
            y_test_pred = model.predict(X_test)
            
            # è©•ä¼°æŒ‡æ¨™
            train_acc = accuracy_score(y_train, y_train_pred)
            test_acc = accuracy_score(y_test, y_test_pred)
            
            if len(target_names) == 2:
                train_f1 = f1_score(y_train, y_train_pred)
                test_f1 = f1_score(y_test, y_test_pred)
            else:
                train_f1 = f1_score(y_train, y_train_pred, average='weighted')
                test_f1 = f1_score(y_test, y_test_pred, average='weighted')
            
            # é¡¯ç¤ºçµæœ
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Train-Data æº–ç¢ºç‡", f"{train_acc:.4f}")
            with col2:
                st.metric("Test-Data æº–ç¢ºç‡", f"{test_acc:.4f}")
            with col3:
                st.metric("Train-Data F1", f"{train_f1:.4f}")
            with col4:
                st.metric("Test-Data F1", f"{test_f1:.4f}")
            
            # éæ“¬åˆæª¢æ¸¬
            overfitting_gap = train_acc - test_acc
            if overfitting_gap > 0.15:
                st.warning(f"âš ï¸ æ±ºç­–æ¨¹éæ“¬åˆåš´é‡ï¼æº–ç¢ºç‡å·®è·ï¼š{overfitting_gap:.4f}")
            else:
                st.success("âœ… æ¨¡å‹è¡¨ç¾è‰¯å¥½ï¼")
            
            # æ··æ·†çŸ©é™£
            st.markdown("### ğŸ“Š æ··æ·†çŸ©é™£")
            
            col1, col2 = st.columns(2)
            
            with col1:
                cm_train = confusion_matrix(y_train, y_train_pred)
                fig = px.imshow(cm_train, 
                               text_auto=True, 
                               x=target_names, 
                               y=target_names,
                               title="Training Data æ··æ·†çŸ©é™£")
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                cm_test = confusion_matrix(y_test, y_test_pred)
                fig = px.imshow(cm_test, 
                               text_auto=True, 
                               x=target_names, 
                               y=target_names,
                               title="Test Data æ··æ·†çŸ©é™£")
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
            
            # ç‰¹å¾µé‡è¦æ€§
            st.markdown("### ğŸ“Š ç‰¹å¾µé‡è¦æ€§åˆ†æ")
            
            feature_importance = pd.DataFrame({
                'ç‰¹å¾µ': selected_features,
                'é‡è¦æ€§': model.feature_importances_
            }).sort_values('é‡è¦æ€§', ascending=False)
            
            fig = go.Figure(data=[
                go.Bar(x=feature_importance['ç‰¹å¾µ'], y=feature_importance['é‡è¦æ€§'],
                       marker_color='green')
            ])
            fig.update_layout(
                title="æ±ºç­–æ¨¹ç‰¹å¾µé‡è¦æ€§",
                xaxis_title="ç‰¹å¾µ",
                yaxis_title="é‡è¦æ€§",
                xaxis_tickangle=45
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # æ¨¹çš„çµæ§‹ä¿¡æ¯
            st.info(f"**æ±ºç­–æ¨¹çµæ§‹ï¼š** å¯¦éš›æ·±åº¦={model.get_depth()}, è‘‰ç¯€é»æ•¸={model.get_n_leaves()}")

elif page == "ğŸŒ² éš¨æ©Ÿæ£®æ—åˆ†é¡":
    st.markdown('<h1 class="main-header">ğŸŒ² éš¨æ©Ÿæ£®æ—åˆ†é¡ (Random Forest Classification)</h1>', unsafe_allow_html=True)
    
    st.markdown("## ğŸ§® æ•¸å­¸åŸç†")
    
    st.markdown("### ğŸŒ² éš¨æ©Ÿæ£®æ—çš„åŸºæœ¬æ¦‚å¿µ")
    st.markdown("éš¨æ©Ÿæ£®æ—æ˜¯å¤šå€‹æ±ºç­–æ¨¹çš„é›†æˆï¼Œé€šéæŠ•ç¥¨ä¾†æ±ºå®šæœ€çµ‚åˆ†é¡ï¼š")
    
    st.latex(r'''
    \hat{y} = \text{mode}(\{T_1(x), T_2(x), ..., T_B(x)\})
    ''')
    
    st.markdown("### ğŸ² Bootstrap + éš¨æ©Ÿç‰¹å¾µ")
    st.markdown("æ¯æ£µæ¨¹ä½¿ç”¨ï¼š")
    st.markdown("1. **BootstrapæŠ½æ¨£**ï¼šéš¨æ©ŸæŠ½å–æ¨£æœ¬ï¼ˆæœ‰æ”¾å›ï¼‰")
    st.markdown("2. **éš¨æ©Ÿç‰¹å¾µå­é›†**ï¼šæ¯æ¬¡åˆ†å‰²éš¨æ©Ÿé¸æ“‡ç‰¹å¾µ")
    
    st.latex(r'''
    \text{æ¯å€‹åˆ†å‰²é»ä½¿ç”¨} \approx \sqrt{p} \text{å€‹éš¨æ©Ÿç‰¹å¾µ}
    ''')
    
    # å„ªç¼ºé»
    col1, col2 = st.columns(2)
    
    with col1:
        st.success("### âœ… å„ªé»")
        st.markdown("""
        - ğŸ›¡ï¸ **æ¸›å°‘éæ“¬åˆ**ï¼šé›†æˆå¤šæ£µæ¨¹
        - ğŸ“Š **æä¾›ç‰¹å¾µé‡è¦æ€§**ï¼šé‡åŒ–ç‰¹å¾µè²¢ç»
        - ğŸ’¾ **è™•ç†å¤§æ•¸æ“šé›†**ï¼šé«˜æ•ˆç®—æ³•
        - ğŸ¯ **å°é›¢ç¾¤å€¼ç©©å¥**ï¼šå¤šæ•¸æ±ºå®š
        - âš¡ **å¯ä¸¦è¡Œè¨“ç·´**ï¼šç¨ç«‹å»ºæ¨¹
        - ğŸ“ˆ **æä¾›OOBä¼°è¨ˆ**ï¼šå…§å»ºé©—è­‰
        """)
    
    with col2:
        st.error("### âŒ ç¼ºé»")
        st.markdown("""
        - ğŸ” **æ¨¡å‹ä¸å¯è§£é‡‹**ï¼šé»‘ç›’æ€§è³ª
        - ğŸ’¿ **è¨˜æ†¶é«”éœ€æ±‚å¤§**ï¼šå­˜å„²å¤šæ£µæ¨¹
        - â±ï¸ **é æ¸¬æ™‚é–“è¼ƒé•·**ï¼šå¤šå€‹æ¨¡å‹é æ¸¬
        - ğŸ“‰ **å¯èƒ½åœ¨å™ªè²æ•¸æ“šä¸Šéæ“¬åˆ**ï¼šå­¸ç¿’å™ªè²
        """)
    
    st.markdown("## ğŸ›ï¸ äº’å‹•å¼å¯¦é©—")
    
    X, y, target_names = get_current_data()
    
    if len(X) > 0:
        # åƒæ•¸è¨­ç½®
        col1, col2 = st.columns(2)
        
        with col1:
            n_estimators = st.slider("æ¨¹çš„æ•¸é‡ï¼š", 10, 200, 100, 10)
            max_depth = st.slider("æœ€å¤§æ·±åº¦ï¼š", 3, 20, 10)
        
        with col2:
            min_samples_split = st.slider("æœ€å°åˆ†å‰²æ¨£æœ¬æ•¸ï¼š", 2, 20, 2)
            test_size = st.slider("æ¸¬è©¦é›†æ¯”ä¾‹ï¼š", 0.1, 0.5, 0.2, 0.05)
        
        # ç‰¹å¾µé¸æ“‡
        selected_features = st.multiselect(
            "é¸æ“‡ç”¨æ–¼å»ºæ¨¡çš„ç‰¹å¾µï¼š",
            X.columns.tolist(),
            default=X.columns.tolist()
        )
        
        if len(selected_features) > 0:
            X_selected = X[selected_features]
            
            # æ•¸æ“šåˆ†å‰²
            X_train, X_test, y_train, y_test = train_test_split(
                X_selected, y, test_size=test_size, random_state=42
            )
            
            # å»ºç«‹æ¨¡å‹
            model = RandomForestClassifier(
                n_estimators=n_estimators,
                max_depth=max_depth,
                min_samples_split=min_samples_split,
                random_state=42,
                n_jobs=-1
            )
            model.fit(X_train, y_train)
            
            # é æ¸¬
            y_train_pred = model.predict(X_train)
            y_test_pred = model.predict(X_test)
            y_train_proba = model.predict_proba(X_train)
            y_test_proba = model.predict_proba(X_test)
            
            # è©•ä¼°æŒ‡æ¨™
            train_acc = accuracy_score(y_train, y_train_pred)
            test_acc = accuracy_score(y_test, y_test_pred)
            
            if len(target_names) == 2:
                train_f1 = f1_score(y_train, y_train_pred)
                test_f1 = f1_score(y_test, y_test_pred)
            else:
                train_f1 = f1_score(y_train, y_train_pred, average='weighted')
                test_f1 = f1_score(y_test, y_test_pred, average='weighted')
            
            # é¡¯ç¤ºçµæœ
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Train-Data æº–ç¢ºç‡", f"{train_acc:.4f}")
            with col2:
                st.metric("Test-Data æº–ç¢ºç‡", f"{test_acc:.4f}")
            with col3:
                st.metric("Train-Data F1", f"{train_f1:.4f}")
            with col4:
                st.metric("Test-Data F1", f"{test_f1:.4f}")
            
            # ç©©å®šæ€§åˆ†æ
            stability_gap = train_acc - test_acc
            if stability_gap > 0.1:
                st.warning(f"âš ï¸ æ¨¡å‹å¯èƒ½è¼•å¾®éæ“¬åˆï¼Œæº–ç¢ºç‡å·®è·ï¼š{stability_gap:.4f}")
            else:
                st.success("âœ… éš¨æ©Ÿæ£®æ—æ¨¡å‹ç©©å®šæ€§è‰¯å¥½ï¼")
            
            # æ··æ·†çŸ©é™£
            st.markdown("### ğŸ“Š æ··æ·†çŸ©é™£")
            
            col1, col2 = st.columns(2)
            
            with col1:
                cm_train = confusion_matrix(y_train, y_train_pred)
                fig = px.imshow(cm_train, 
                               text_auto=True, 
                               x=target_names, 
                               y=target_names,
                               title="Training Data æ··æ·†çŸ©é™£")
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                cm_test = confusion_matrix(y_test, y_test_pred)
                fig = px.imshow(cm_test, 
                               text_auto=True, 
                               x=target_names, 
                               y=target_names,
                               title="Test Data æ··æ·†çŸ©é™£")
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
            
            # ç‰¹å¾µé‡è¦æ€§åˆ†æ
            st.markdown("### ğŸ“Š ç‰¹å¾µé‡è¦æ€§åˆ†æ")
            
            feature_importance = pd.DataFrame({
                'ç‰¹å¾µ': selected_features,
                'é‡è¦æ€§': model.feature_importances_
            }).sort_values('é‡è¦æ€§', ascending=False)
            
            fig = go.Figure(data=[
                go.Bar(x=feature_importance['ç‰¹å¾µ'], y=feature_importance['é‡è¦æ€§'],
                       marker_color='forestgreen')
            ])
            fig.update_layout(
                title=f"éš¨æ©Ÿæ£®æ—ç‰¹å¾µé‡è¦æ€§ ({n_estimators}æ£µæ¨¹)",
                xaxis_title="ç‰¹å¾µ",
                yaxis_title="é‡è¦æ€§",
                xaxis_tickangle=45
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # é æ¸¬æ¦‚ç‡åˆ†å¸ƒ
            if len(target_names) <= 5:  # åªåœ¨é¡åˆ¥ä¸å¤ªå¤šæ™‚é¡¯ç¤º
                st.markdown("### ğŸ“ˆ é æ¸¬æ¦‚ç‡åˆ†å¸ƒ")
                
                fig = go.Figure()
                for i, class_name in enumerate(target_names):
                    fig.add_trace(go.Histogram(
                        x=y_test_proba[:, i],
                        name=f'{class_name}',
                        opacity=0.7,
                        nbinsx=20
                    ))
                
                fig.update_layout(
                    title="æ¸¬è©¦é›†é æ¸¬æ¦‚ç‡åˆ†å¸ƒ",
                    xaxis_title="é æ¸¬æ¦‚ç‡",
                    yaxis_title="é »ç‡",
                    height=400
                )
                st.plotly_chart(fig, use_container_width=True)
            
            st.info(f"**éš¨æ©Ÿæ£®æ—é…ç½®ï¼š** {n_estimators}æ£µæ¨¹, æœ€å¤§æ·±åº¦={max_depth}")

elif page == "ğŸ“ è©•åƒ¹æŒ‡æ¨™è©³è§£":
    st.markdown('<h1 class="main-header">ğŸ“ è©•åƒ¹æŒ‡æ¨™è©³è§£</h1>', unsafe_allow_html=True)
    
    st.markdown("## ğŸ¯ åˆ†é¡è©•åƒ¹æŒ‡æ¨™æ¦‚è¿°")
    st.info("ğŸ’¡ è©•åƒ¹æŒ‡æ¨™å¹«åŠ©æˆ‘å€‘é‡åŒ–åˆ†é¡æ¨¡å‹çš„æ€§èƒ½ï¼Œé¸æ“‡åˆé©çš„æŒ‡æ¨™å°æ¨¡å‹è©•ä¼°è‡³é—œé‡è¦ã€‚")
    
    # å‰µå»ºæ¨™ç±¤é å¼ä½ˆå±€
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ”µ æ··æ·†çŸ©é™£", "ğŸŸ¡ æº–ç¢ºç‡ & ç²¾ç¢ºç‡", "ğŸŸ¢ å¬å›ç‡ & F1åˆ†æ•¸", "ğŸ”´ ROC-AUC", "ğŸŸ£ å¤šåˆ†é¡æŒ‡æ¨™"])
    
    with tab1:
        st.markdown("### ğŸ”µ æ··æ·†çŸ©é™£ (Confusion Matrix)")
        
        st.markdown("æ··æ·†çŸ©é™£æ˜¯åˆ†é¡å•é¡Œè©•ä¼°çš„åŸºç¤ï¼Œå±•ç¤ºé æ¸¬çµæœèˆ‡çœŸå¯¦æ¨™ç±¤çš„å°æ¯”ï¼š")
        
        # äºŒåˆ†é¡æ··æ·†çŸ©é™£
        st.markdown("#### ğŸ“Š äºŒåˆ†é¡æ··æ·†çŸ©é™£")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # å‰µå»ºç¤ºä¾‹æ··æ·†çŸ©é™£
            cm_example = np.array([[85, 15], [10, 90]])
            fig = px.imshow(cm_example, 
                           text_auto=True,
                           x=['é æ¸¬: è² é¡', 'é æ¸¬: æ­£é¡'],
                           y=['å¯¦éš›: è² é¡', 'å¯¦éš›: æ­£é¡'],
                           title="äºŒåˆ†é¡æ··æ·†çŸ©é™£ç¤ºä¾‹",
                           color_continuous_scale='Blues')
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.markdown("**æ··æ·†çŸ©é™£è¡“èªï¼š**")
            st.markdown("- **TN (True Negative)**: 85")
            st.markdown("- **FP (False Positive)**: 15") 
            st.markdown("- **FN (False Negative)**: 10")
            st.markdown("- **TP (True Positive)**: 90")
            
            st.info("**ç¸½æº–ç¢ºç‡**: (85+90)/(85+15+10+90) = 87.5%")
        
        # æ•¸å­¸å®šç¾©
        st.markdown("#### ğŸ“ æ•¸å­¸å®šç¾©")
        st.latex(r'''
        \begin{pmatrix}
        TN & FP \\
        FN & TP
        \end{pmatrix}
        ''')
        
        st.markdown("å…¶ä¸­ï¼š")
        st.markdown("- **TN**: çœŸé™°æ€§ - æ­£ç¢ºé æ¸¬ç‚ºè² é¡")
        st.markdown("- **FP**: å‡é™½æ€§ - éŒ¯èª¤é æ¸¬ç‚ºæ­£é¡ï¼ˆç¬¬ä¸€é¡éŒ¯èª¤ï¼‰")
        st.markdown("- **FN**: å‡é™°æ€§ - éŒ¯èª¤é æ¸¬ç‚ºè² é¡ï¼ˆç¬¬äºŒé¡éŒ¯èª¤ï¼‰")
        st.markdown("- **TP**: çœŸé™½æ€§ - æ­£ç¢ºé æ¸¬ç‚ºæ­£é¡")
        
        # æ··æ·†çŸ©é™£çš„æŒ‡æ¨™é¸æ“‡å»ºè­°
        st.markdown("---")
        st.markdown("### ğŸ¯ æ··æ·†çŸ©é™£çš„æ‡‰ç”¨å»ºè­°")
        st.success("""
        **ä½•æ™‚ä½¿ç”¨æ··æ·†çŸ©é™£ï¼š**
        - ğŸ” **è©³ç´°éŒ¯èª¤åˆ†æ**ï¼šäº†è§£å…·é«”éŒ¯èª¤é¡å‹
        - ğŸ“Š **å¤šåˆ†é¡å•é¡Œ**ï¼šæŸ¥çœ‹é¡åˆ¥é–“çš„æ··æ·†æƒ…æ³
        - ğŸ¯ **æ¨¡å‹è¨ºæ–·**ï¼šè­˜åˆ¥æ¨¡å‹çš„å¼±é»
        - ğŸ’¡ **æ”¹é€²æ–¹å‘**ï¼šæŒ‡å°æ•¸æ“šæ”¶é›†å’Œç‰¹å¾µå·¥ç¨‹
        """)
    
    with tab2:
        st.markdown("### ğŸŸ¡ æº–ç¢ºç‡ (Accuracy) & ç²¾ç¢ºç‡ (Precision)")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### ğŸ¯ æº–ç¢ºç‡ (Accuracy)")
            st.markdown("æº–ç¢ºç‡æ˜¯æœ€ç›´è§€çš„è©•åƒ¹æŒ‡æ¨™ï¼Œè¡¨ç¤ºé æ¸¬æ­£ç¢ºçš„æ¯”ä¾‹ï¼š")
            
            st.latex(r'''
            Accuracy = \frac{TP + TN}{TP + TN + FP + FN}
            ''')
            
            st.success("### ğŸ“Š æº–ç¢ºç‡ç‰¹é»")
            st.markdown("""
            - **ç¯„åœ**: 0-1 (è¶Šé«˜è¶Šå¥½)
            - **é©ç”¨**: é¡åˆ¥å¹³è¡¡çš„æ•¸æ“šé›†
            - **å„ªé»**: ç›´è§€æ˜“æ‡‚
            - **ç¼ºé»**: åœ¨ä¸å¹³è¡¡æ•¸æ“šä¸­æœƒèª¤å°
            """)
        
        with col2:
            st.markdown("#### ğŸ¯ ç²¾ç¢ºç‡ (Precision)")
            st.markdown("ç²¾ç¢ºç‡é—œæ³¨ã€Œé æ¸¬ç‚ºæ­£é¡ä¸­ï¼Œæœ‰å¤šå°‘çœŸçš„æ˜¯æ­£é¡ã€ï¼š")
            
            st.latex(r'''
            Precision = \frac{TP}{TP + FP}
            ''')
            
            st.warning("### ğŸ“Š ç²¾ç¢ºç‡ç‰¹é»")
            st.markdown("""
            - **ç¯„åœ**: 0-1 (è¶Šé«˜è¶Šå¥½)
            - **é—œæ³¨**: æ¸›å°‘å‡é™½æ€§
            - **é©ç”¨**: å‡é™½æ€§ä»£åƒ¹é«˜çš„å ´æ™¯
            - **ä¾‹å­**: åƒåœ¾éƒµä»¶åµæ¸¬
            """)
        
        # å¯¦éš›è¨ˆç®—ç¤ºä¾‹
        st.markdown("#### ğŸ§® å¯¦éš›è¨ˆç®—ç¤ºä¾‹")
        
        X, y, target_names = get_current_data()
        
        if len(X) > 0 and len(target_names) >= 2:
            # ç°¡å–®è¨“ç·´ä¸€å€‹æ¨¡å‹é€²è¡Œæ¼”ç¤º
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
            
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            model = LogisticRegression(random_state=42)
            model.fit(X_train_scaled, y_train)
            y_pred = model.predict(X_test_scaled)
            
            # è¨ˆç®—æŒ‡æ¨™
            acc = accuracy_score(y_test, y_pred)
            
            if len(target_names) == 2:
                prec = precision_score(y_test, y_pred)
            else:
                prec = precision_score(y_test, y_pred, average='weighted')
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("æº–ç¢ºç‡", f"{acc:.4f}")
            with col2:
                st.metric("ç²¾ç¢ºç‡", f"{prec:.4f}")
        
        # æº–ç¢ºç‡å’Œç²¾ç¢ºç‡çš„æŒ‡æ¨™é¸æ“‡å»ºè­°
        st.markdown("---")
        st.markdown("### ğŸ¯ æº–ç¢ºç‡ & ç²¾ç¢ºç‡çš„é¸æ“‡å»ºè­°")
        
        col1, col2 = st.columns(2)
        with col1:
            st.success("""
            **é¸æ“‡æº–ç¢ºç‡ç•¶ï¼š**
            - âœ… é¡åˆ¥ç›¸å°å¹³è¡¡
            - âœ… æ‰€æœ‰éŒ¯èª¤ä»£åƒ¹ç›¸åŒ
            - âœ… éœ€è¦æ•´é«”æ€§èƒ½æ¦‚è¦½
            - âœ… å‘åˆ©ç›Šç›¸é—œè€…å ±å‘Š
            """)
        
        with col2:
            st.warning("""
            **é¸æ“‡ç²¾ç¢ºç‡ç•¶ï¼š**
            - âš ï¸ å‡é™½æ€§ä»£åƒ¹å¾ˆé«˜
            - ğŸ“§ åƒåœ¾éƒµä»¶åµæ¸¬
            - ğŸ›’ æ¨è–¦ç³»çµ±
            - ğŸ¯ éœ€è¦é«˜ç¢ºä¿¡åº¦çš„é æ¸¬
            """)
    
    with tab3:
        st.markdown("### ğŸŸ¢ å¬å›ç‡ (Recall) & F1åˆ†æ•¸")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### ğŸ” å¬å›ç‡ (Recall)")
            st.markdown("å¬å›ç‡é—œæ³¨ã€Œå¯¦éš›æ­£é¡ä¸­ï¼Œæœ‰å¤šå°‘è¢«æ­£ç¢ºé æ¸¬ã€ï¼š")
            
            st.latex(r'''
            Recall = \frac{TP}{TP + FN}
            ''')
            
            st.success("### ğŸ“Š å¬å›ç‡ç‰¹é»")
            st.markdown("""
            - **ç¯„åœ**: 0-1 (è¶Šé«˜è¶Šå¥½)
            - **é—œæ³¨**: æ¸›å°‘å‡é™°æ€§
            - **é©ç”¨**: å‡é™°æ€§ä»£åƒ¹é«˜çš„å ´æ™¯
            - **ä¾‹å­**: ç–¾ç—…è¨ºæ–·
            """)
        
        with col2:
            st.markdown("#### âš–ï¸ F1åˆ†æ•¸")
            st.markdown("F1åˆ†æ•¸æ˜¯ç²¾ç¢ºç‡å’Œå¬å›ç‡çš„èª¿å’Œå¹³å‡ï¼š")
            
            st.latex(r'''
            F1 = 2 \times \frac{Precision \times Recall}{Precision + Recall}
            ''')
            
            st.info("### ğŸ“Š F1åˆ†æ•¸ç‰¹é»")
            st.markdown("""
            - **ç¯„åœ**: 0-1 (è¶Šé«˜è¶Šå¥½)
            - **å¹³è¡¡**: ç²¾ç¢ºç‡å’Œå¬å›ç‡
            - **é©ç”¨**: ä¸å¹³è¡¡æ•¸æ“šé›†
            - **å„ªé»**: ç¶œåˆè€ƒæ…®å…©å€‹æŒ‡æ¨™
            """)
        
        # Precision-Recallæ¬Šè¡¡
        st.markdown("#### âš–ï¸ Precision-Recall æ¬Šè¡¡")
        st.markdown("ç²¾ç¢ºç‡å’Œå¬å›ç‡é€šå¸¸å­˜åœ¨æ¬Šè¡¡é—œä¿‚ï¼š")
        
        # å‰µå»ºç¤ºä¾‹æ¬Šè¡¡åœ–
        thresholds = np.linspace(0.1, 0.9, 20)
        precision_sim = 1 - 0.5 * thresholds + 0.1 * np.random.randn(20)
        recall_sim = thresholds + 0.1 * np.random.randn(20)
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=thresholds, y=precision_sim, mode='lines+markers', name='Precision'))
        fig.add_trace(go.Scatter(x=thresholds, y=recall_sim, mode='lines+markers', name='Recall'))
        fig.update_layout(
            title="Precision vs Recall æ¬Šè¡¡",
            xaxis_title="åˆ†é¡é–¾å€¼",
            yaxis_title="åˆ†æ•¸",
            height=400
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # å¬å›ç‡å’ŒF1åˆ†æ•¸çš„æŒ‡æ¨™é¸æ“‡å»ºè­°
        st.markdown("---")
        st.markdown("### ğŸ¯ å¬å›ç‡ & F1åˆ†æ•¸çš„é¸æ“‡å»ºè­°")
        
        col1, col2 = st.columns(2)
        with col1:
            st.error("""
            **é¸æ“‡å¬å›ç‡ç•¶ï¼š**
            - ğŸš¨ å‡é™°æ€§ä»£åƒ¹æ¥µé«˜
            - ğŸ©º ç–¾ç—…è¨ºæ–·
            - ğŸ” æ¬ºè©æª¢æ¸¬
            - ğŸ›¡ï¸ å®‰å…¨ç³»çµ±
            """)
        
        with col2:
            st.info("""
            **é¸æ“‡F1åˆ†æ•¸ç•¶ï¼š**
            - âš–ï¸ éœ€è¦å¹³è¡¡ç²¾ç¢ºç‡å’Œå¬å›ç‡
            - ğŸ“Š æ•¸æ“šä¸å¹³è¡¡
            - ğŸ¯ ç¶œåˆè©•ä¼°æ¨¡å‹
            - ğŸ† æ¨¡å‹æ¯”è¼ƒ
            """)
    
    with tab4:
        st.markdown("### ğŸ”´ ROCæ›²ç·šèˆ‡AUC")
        
        st.markdown("#### ğŸ“ˆ ROCæ›²ç·š (Receiver Operating Characteristic)")
        st.markdown("ROCæ›²ç·šå±•ç¤ºä¸åŒé–¾å€¼ä¸‹TPRèˆ‡FPRçš„é—œä¿‚ï¼š")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.latex(r'''
            \begin{align}
            TPR &= \frac{TP}{TP + FN} = Recall \\
            FPR &= \frac{FP}{FP + TN}
            \end{align}
            ''')
            
            st.markdown("**TPR (çœŸé™½æ€§ç‡)**: å¬å›ç‡")
            st.markdown("**FPR (å‡é™½æ€§ç‡)**: å‡é™½æ€§ä½”æ‰€æœ‰é™°æ€§çš„æ¯”ä¾‹")
        
        with col2:
            st.markdown("#### ğŸ“Š AUC (Area Under Curve)")
            st.latex(r'''
            AUC = \int_0^1 TPR(FPR^{-1}(x)) dx
            ''')
            
            st.markdown("**AUCç¯„åœ**:")
            st.markdown("- **AUC = 1**: å®Œç¾åˆ†é¡å™¨")
            st.markdown("- **AUC = 0.5**: éš¨æ©Ÿåˆ†é¡å™¨")
            st.markdown("- **AUC < 0.5**: æ¯”éš¨æ©Ÿé‚„å·®")
        
        # å‰µå»ºç¤ºä¾‹ROCæ›²ç·š
        fpr_sim = np.linspace(0, 1, 100)
        tpr_sim = np.sqrt(fpr_sim) + 0.2 * np.random.randn(100)
        tpr_sim = np.clip(tpr_sim, 0, 1)
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=fpr_sim, y=tpr_sim, mode='lines', name='ROCæ›²ç·š'))
        fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', line=dict(dash='dash'), name='éš¨æ©Ÿåˆ†é¡å™¨'))
        fig.update_layout(
            title="ROCæ›²ç·šç¤ºä¾‹",
            xaxis_title="False Positive Rate (FPR)",
            yaxis_title="True Positive Rate (TPR)",
            height=400
        )
        st.plotly_chart(fig, use_container_width=True)
        
        st.info("ğŸ’¡ **ROC-AUCé©ç”¨æ–¼**: äºŒåˆ†é¡å•é¡Œï¼Œé¡åˆ¥ç›¸å°å¹³è¡¡çš„æƒ…æ³")
        
        # ROC-AUCçš„æŒ‡æ¨™é¸æ“‡å»ºè­°
        st.markdown("---")
        st.markdown("### ğŸ¯ ROC-AUCçš„é¸æ“‡å»ºè­°")
        
        col1, col2 = st.columns(2)
        with col1:
            st.success("""
            **é¸æ“‡ROC-AUCç•¶ï¼š**
            - ğŸ¯ äºŒåˆ†é¡å•é¡Œ
            - âš–ï¸ é¡åˆ¥ç›¸å°å¹³è¡¡
            - ğŸ“ˆ é—œæ³¨æ•´é«”æ’åºèƒ½åŠ›
            - ğŸ”„ éœ€è¦èª¿æ•´åˆ†é¡é–¾å€¼
            """)
        
        with col2:
            st.warning("""
            **é¿å…ROC-AUCç•¶ï¼š**
            - âš ï¸ åš´é‡é¡åˆ¥ä¸å¹³è¡¡
            - ğŸ“Š å¤šåˆ†é¡å•é¡Œ
            - ğŸ¯ é—œæ³¨ç‰¹å®šé¡åˆ¥æ€§èƒ½
            - ğŸ’¡ æ¨è–¦ä½¿ç”¨PR-AUCæ›¿ä»£
            """)
    
    with tab5:
        st.markdown("### ğŸŸ£ å¤šåˆ†é¡å•é¡ŒæŒ‡æ¨™")
        
        st.markdown("å¤šåˆ†é¡å•é¡Œéœ€è¦ç‰¹æ®Šçš„è©•åƒ¹æ–¹å¼ï¼š")
        
        # å®å¹³å‡ vs å¾®å¹³å‡
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### ğŸ“Š å®å¹³å‡ (Macro Average)")
            st.latex(r'''
            Macro = \frac{1}{n} \sum_{i=1}^{n} Metric_i
            ''')
            
            st.markdown("**ç‰¹é»ï¼š**")
            st.markdown("- æ¯å€‹é¡åˆ¥æ¬Šé‡ç›¸ç­‰")
            st.markdown("- å—å°‘æ•¸é¡åˆ¥å½±éŸ¿å¤§")
            st.markdown("- é©åˆé¡åˆ¥å¹³è¡¡æ•¸æ“š")
        
        with col2:
            st.markdown("#### ğŸ“Š å¾®å¹³å‡ (Micro Average)")
            st.latex(r'''
            Micro = \frac{\sum_{i=1}^{n} TP_i}{\sum_{i=1}^{n} (TP_i + FP_i)}
            ''')
            
            st.markdown("**ç‰¹é»ï¼š**")
            st.markdown("- æ¨£æœ¬æ¬Šé‡ç›¸ç­‰")
            st.markdown("- å—å¤šæ•¸é¡åˆ¥å½±éŸ¿å¤§")
            st.markdown("- é©åˆä¸å¹³è¡¡æ•¸æ“š")
        
        # å¤šåˆ†é¡æ··æ·†çŸ©é™£ç¤ºä¾‹
        st.markdown("#### ğŸ“Š å¤šåˆ†é¡æ··æ·†çŸ©é™£")
        
        if len(target_names) > 2:
            # ä½¿ç”¨çœŸå¯¦æ•¸æ“šå‰µå»ºæ··æ·†çŸ©é™£
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
            
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            model = LogisticRegression(random_state=42, max_iter=1000)
            model.fit(X_train_scaled, y_train)
            y_pred = model.predict(X_test_scaled)
            
            cm = confusion_matrix(y_test, y_pred)
            
            fig = px.imshow(cm, 
                           text_auto=True,
                           x=target_names,
                           y=target_names,
                           title=f"å¤šåˆ†é¡æ··æ·†çŸ©é™£ - {dataset_choice}")
            fig.update_layout(height=500)
            st.plotly_chart(fig, use_container_width=True)
            
            # è¨ˆç®—å„ç¨®å¹³å‡æŒ‡æ¨™
            macro_f1 = f1_score(y_test, y_pred, average='macro')
            micro_f1 = f1_score(y_test, y_pred, average='micro')
            weighted_f1 = f1_score(y_test, y_pred, average='weighted')
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Macro F1", f"{macro_f1:.4f}")
            with col2:
                st.metric("Micro F1", f"{micro_f1:.4f}")
            with col3:
                st.metric("Weighted F1", f"{weighted_f1:.4f}")
        
        # å¤šåˆ†é¡æŒ‡æ¨™çš„é¸æ“‡å»ºè­°
        st.markdown("---")
        st.markdown("### ğŸ¯ å¤šåˆ†é¡æŒ‡æ¨™çš„é¸æ“‡å»ºè­°")
        
        col1, col2 = st.columns(2)
        with col1:
            st.success("""
            **é¸æ“‡Macroå¹³å‡ç•¶ï¼š**
            - âš–ï¸ æ¯å€‹é¡åˆ¥åŒç­‰é‡è¦
            - ğŸ” æƒ³äº†è§£å°‘æ•¸é¡åˆ¥è¡¨ç¾
            - ğŸ“Š é¡åˆ¥ç›¸å°å¹³è¡¡
            - ğŸ¯ é—œæ³¨æ¨¡å‹å°æ‰€æœ‰é¡åˆ¥çš„èƒ½åŠ›
            """)
        
        with col2:
            st.info("""
            **é¸æ“‡Micro/Weightedå¹³å‡ç•¶ï¼š**
            - ğŸ“ˆ é—œæ³¨æ•´é«”æº–ç¢ºæ€§
            - ğŸ¯ æ¨£æœ¬æ•¸é‡é‡è¦
            - âš ï¸ é¡åˆ¥ä¸å¹³è¡¡
            - ğŸ’¼ æ¥­å‹™é—œæ³¨å¤šæ•¸é¡åˆ¥
            """)
    
    # ç§»å‹•åˆ°æ¯å€‹æ¨™ç±¤é å…§çš„æŒ‡æ¨™é¸æ“‡å»ºè­°å·²åœ¨ä¸Šé¢å¯¦ç¾

elif page == "ğŸš€ æ¢¯åº¦æå‡åˆ†é¡":
    st.markdown('<h1 class="main-header">ğŸš€ æ¢¯åº¦æå‡åˆ†é¡ (Gradient Boosting Classification)</h1>', unsafe_allow_html=True)
    
    st.markdown("## ğŸ§® æ•¸å­¸åŸç†")
    
    st.markdown("### ğŸš€ æ¢¯åº¦æå‡çš„åŸºæœ¬æ¦‚å¿µ")
    st.markdown("æ¢¯åº¦æå‡é€šéé€æ­¥æ·»åŠ å¼±å­¸ç¿’å™¨ä¾†æ¸›å°‘é æ¸¬éŒ¯èª¤ï¼š")
    
    st.latex(r'''
    F_m(x) = F_{m-1}(x) + \gamma_m h_m(x)
    ''')
    
    st.markdown("å…¶ä¸­ï¼š")
    st.markdown("- $F_m(x)$: ç¬¬mæ­¥çš„å¼·å­¸ç¿’å™¨")
    st.markdown("- $h_m(x)$: ç¬¬må€‹å¼±å­¸ç¿’å™¨")
    st.markdown("- Î³â‚˜: å­¸ç¿’ç‡")
    
    st.markdown("### ğŸ“Š æå¤±å‡½æ•¸")
    st.latex(r'''
    L(y, F(x)) = -\sum_{k=1}^{K} y_k \log(p_k(x))
    ''')
    
    # å„ªç¼ºé»
    col1, col2 = st.columns(2)
    
    with col1:
        st.success("### âœ… å„ªé»")
        st.markdown("""
        - ğŸ¯ **é æ¸¬æº–ç¢ºç‡é«˜**ï¼šé€šå¸¸è¡¨ç¾å„ªç•°
        - ğŸ“Š **è™•ç†æ··åˆæ•¸æ“š**ï¼šæ•¸å€¼+é¡åˆ¥ç‰¹å¾µ
        - ğŸ›¡ï¸ **å°é›¢ç¾¤å€¼ç©©å¥**ï¼šåŸºæ–¼æ®˜å·®å­¸ç¿’
        - ğŸ”§ **è‡ªå‹•ç‰¹å¾µé¸æ“‡**ï¼šé‡è¦ç‰¹å¾µå„ªå…ˆ
        - ğŸ“ˆ **æä¾›ç‰¹å¾µé‡è¦æ€§**ï¼šå¯è§£é‡‹æ€§
        """)
    
    with col2:
        st.error("### âŒ ç¼ºé»")
        st.markdown("""
        - â±ï¸ **è¨“ç·´æ™‚é–“é•·**ï¼šé †åºå­¸ç¿’
        - âš ï¸ **å®¹æ˜“éæ“¬åˆ**ï¼šéœ€è¦èª¿åƒ
        - ğŸ›ï¸ **è¶…åƒæ•¸å¤š**ï¼šèª¿åƒè¤‡é›œ
        - ğŸ’¿ **è¨˜æ†¶é«”éœ€æ±‚å¤§**ï¼šå­˜å„²å¤šå€‹æ¨¡å‹
        """)
    
    st.markdown("## ğŸ›ï¸ äº’å‹•å¼å¯¦é©—")
    
    X, y, target_names = get_current_data()
    
    if len(X) > 0:
        # åƒæ•¸è¨­ç½®
        col1, col2 = st.columns(2)
        
        with col1:
            n_estimators = st.slider("å¼±å­¸ç¿’å™¨æ•¸é‡ï¼š", 10, 200, 100, 10)
            learning_rate = st.slider("å­¸ç¿’ç‡ï¼š", 0.01, 0.3, 0.1, 0.01)
        
        with col2:
            max_depth = st.slider("æ¨¹çš„æœ€å¤§æ·±åº¦ï¼š", 1, 10, 3)
            test_size = st.slider("æ¸¬è©¦é›†æ¯”ä¾‹ï¼š", 0.1, 0.5, 0.2, 0.05)
        
        # ç‰¹å¾µé¸æ“‡
        selected_features = st.multiselect(
            "é¸æ“‡ç”¨æ–¼å»ºæ¨¡çš„ç‰¹å¾µï¼š",
            X.columns.tolist(),
            default=X.columns.tolist()[:6]
        )
        
        if len(selected_features) > 0:
            X_selected = X[selected_features]
            
            # æ•¸æ“šåˆ†å‰²
            X_train, X_test, y_train, y_test = train_test_split(
                X_selected, y, test_size=test_size, random_state=42
            )
            
            # å»ºç«‹æ¨¡å‹
            model = GradientBoostingClassifier(
                n_estimators=n_estimators,
                learning_rate=learning_rate,
                max_depth=max_depth,
                random_state=42
            )
            
            with st.spinner('è¨“ç·´æ¢¯åº¦æå‡æ¨¡å‹ä¸­...'):
                model.fit(X_train, y_train)
            
            # é æ¸¬
            y_train_pred = model.predict(X_train)
            y_test_pred = model.predict(X_test)
            
            # è©•ä¼°æŒ‡æ¨™
            train_acc = accuracy_score(y_train, y_train_pred)
            test_acc = accuracy_score(y_test, y_test_pred)
            
            if len(target_names) == 2:
                train_f1 = f1_score(y_train, y_train_pred)
                test_f1 = f1_score(y_test, y_test_pred)
            else:
                train_f1 = f1_score(y_train, y_train_pred, average='weighted')
                test_f1 = f1_score(y_test, y_test_pred, average='weighted')
            
            # é¡¯ç¤ºçµæœ
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Train-Data æº–ç¢ºç‡", f"{train_acc:.4f}")
            with col2:
                st.metric("Test-Data æº–ç¢ºç‡", f"{test_acc:.4f}")
            with col3:
                st.metric("Train-Data F1", f"{train_f1:.4f}")
            with col4:
                st.metric("Test-Data F1", f"{test_f1:.4f}")
            
            # æ··æ·†çŸ©é™£
            st.markdown("### ğŸ“Š æ··æ·†çŸ©é™£")
            
            col1, col2 = st.columns(2)
            
            with col1:
                cm_train = confusion_matrix(y_train, y_train_pred)
                fig = px.imshow(cm_train, 
                               text_auto=True, 
                               x=target_names, 
                               y=target_names,
                               title="Training Data æ··æ·†çŸ©é™£")
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                cm_test = confusion_matrix(y_test, y_test_pred)
                fig = px.imshow(cm_test, 
                               text_auto=True, 
                               x=target_names, 
                               y=target_names,
                               title="Test Data æ··æ·†çŸ©é™£")
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
            
            # ç‰¹å¾µé‡è¦æ€§åˆ†æ
            st.markdown("### ğŸ“Š ç‰¹å¾µé‡è¦æ€§åˆ†æ")
            
            feature_importance = pd.DataFrame({
                'ç‰¹å¾µ': selected_features,
                'é‡è¦æ€§': model.feature_importances_
            }).sort_values('é‡è¦æ€§', ascending=False)
            
            fig = go.Figure(data=[
                go.Bar(x=feature_importance['ç‰¹å¾µ'], y=feature_importance['é‡è¦æ€§'],
                       marker_color='orange')
            ])
            fig.update_layout(
                title=f"æ¢¯åº¦æå‡ç‰¹å¾µé‡è¦æ€§ (å­¸ç¿’ç‡={learning_rate})",
                xaxis_title="ç‰¹å¾µ",
                yaxis_title="é‡è¦æ€§",
                xaxis_tickangle=45
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # å­¸ç¿’æ›²ç·š
            st.markdown("### ğŸ“ˆ å­¸ç¿’æ›²ç·š")
            
            train_scores = []
            test_scores = []
            
            for i, (train_pred, test_pred) in enumerate(zip(
                model.staged_predict(X_train), 
                model.staged_predict(X_test)
            )):
                train_scores.append(accuracy_score(y_train, train_pred))
                test_scores.append(accuracy_score(y_test, test_pred))
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=list(range(1, len(train_scores)+1)), y=train_scores, 
                                   mode='lines', name='Training Accuracy'))
            fig.add_trace(go.Scatter(x=list(range(1, len(test_scores)+1)), y=test_scores, 
                                   mode='lines', name='Test Accuracy'))
            fig.update_layout(
                title="æ¢¯åº¦æå‡å­¸ç¿’æ›²ç·š",
                xaxis_title="è¿­ä»£æ¬¡æ•¸",
                yaxis_title="æº–ç¢ºç‡",
                height=400
            )
            st.plotly_chart(fig, use_container_width=True)

elif page == "ğŸ¯ æ”¯æŒå‘é‡æ©Ÿ":
    st.markdown('<h1 class="main-header">ğŸ¯ æ”¯æŒå‘é‡æ©Ÿ (Support Vector Machine)</h1>', unsafe_allow_html=True)
    
    st.markdown("## ğŸ§® æ•¸å­¸åŸç†")
    
    st.markdown("### ğŸ¯ SVMçš„åŸºæœ¬æ¦‚å¿µ")
    st.markdown("SVMå°‹æ‰¾æœ€å¤§é–“éš”çš„æ±ºç­–é‚Šç•Œï¼š")
    
    st.latex(r'''
    \max \frac{2}{||\mathbf{w}||} \quad \text{subject to } y_i(\mathbf{w} \cdot \mathbf{x}_i + b) \geq 1
    ''')
    
    st.markdown("### ğŸ“Š æ ¸å‡½æ•¸")
    st.markdown("å¸¸ç”¨æ ¸å‡½æ•¸ï¼š")
    
    st.latex(r'''
    \begin{align}
    \text{ç·šæ€§æ ¸ï¼š} K(x, x') &= x \cdot x' \\
    \text{å¤šé …å¼æ ¸ï¼š} K(x, x') &= (x \cdot x' + c)^d \\
    \text{RBFæ ¸ï¼š} K(x, x') &= \exp(-\gamma ||x - x'||^2)
    \end{align}
    ''')
    
    # å„ªç¼ºé»
    col1, col2 = st.columns(2)
    
    with col1:
        st.success("### âœ… å„ªé»")
        st.markdown("""
        - ğŸ¯ **é«˜ç¶­ç©ºé–“æœ‰æ•ˆ**ï¼šé©åˆç‰¹å¾µå¤šçš„æ•¸æ“š
        - ğŸ›¡ï¸ **è¨˜æ†¶é«”æ•ˆç‡é«˜**ï¼šåªä½¿ç”¨æ”¯æŒå‘é‡
        - ğŸ”§ **æ ¸æŠ€å·§**ï¼šè™•ç†éç·šæ€§å•é¡Œ
        - ğŸ“Š **æ³›åŒ–èƒ½åŠ›å¼·**ï¼šæœ€å¤§é–“éš”åŸç†
        """)
    
    with col2:
        st.error("### âŒ ç¼ºé»")
        st.markdown("""
        - â±ï¸ **å¤§æ•¸æ“šé›†æ…¢**ï¼šæ™‚é–“è¤‡é›œåº¦é«˜
        - ğŸ›ï¸ **åƒæ•¸æ•æ„Ÿ**ï¼šéœ€è¦èª¿æ•´Cå’Œgamma
        - ğŸ“ˆ **ä¸æä¾›æ¦‚ç‡**ï¼šéœ€è¦é¡å¤–è¨ˆç®—
        - ğŸ”Š **å°å™ªè²æ•æ„Ÿ**ï¼šé›¢ç¾¤å€¼å½±éŸ¿å¤§
        """)
    
    st.markdown("## ğŸ›ï¸ äº’å‹•å¼å¯¦é©—")
    
    X, y, target_names = get_current_data()
    
    if len(X) > 0:
        # åƒæ•¸è¨­ç½®
        col1, col2 = st.columns(2)
        
        with col1:
            kernel = st.selectbox("æ ¸å‡½æ•¸ï¼š", ["linear", "poly", "rbf", "sigmoid"])
            C = st.slider("æ­£å‰‡åŒ–åƒæ•¸ Cï¼š", 0.01, 10.0, 1.0, 0.01)
        
        with col2:
            if kernel in ["poly", "rbf", "sigmoid"]:
                gamma = st.selectbox("Gammaï¼š", ["scale", "auto"])
            else:
                gamma = "scale"
            test_size = st.slider("æ¸¬è©¦é›†æ¯”ä¾‹ï¼š", 0.1, 0.5, 0.2, 0.05)
        
        # ç‰¹å¾µé¸æ“‡
        selected_features = st.multiselect(
            "é¸æ“‡ç”¨æ–¼å»ºæ¨¡çš„ç‰¹å¾µï¼š",
            X.columns.tolist(),
            default=X.columns.tolist()[:4]
        )
        
        if len(selected_features) > 0:
            X_selected = X[selected_features]
            
            # æ•¸æ“šåˆ†å‰²
            X_train, X_test, y_train, y_test = train_test_split(
                X_selected, y, test_size=test_size, random_state=42
            )
            
            # æ¨™æº–åŒ–ï¼ˆSVMéœ€è¦æ¨™æº–åŒ–ï¼‰
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # å»ºç«‹æ¨¡å‹
            model = SVC(
                kernel=kernel,
                C=C,
                gamma=gamma,
                random_state=42
            )
            
            with st.spinner('è¨“ç·´SVMæ¨¡å‹ä¸­...'):
                model.fit(X_train_scaled, y_train)
            
            # é æ¸¬
            y_train_pred = model.predict(X_train_scaled)
            y_test_pred = model.predict(X_test_scaled)
            
            # è©•ä¼°æŒ‡æ¨™
            train_acc = accuracy_score(y_train, y_train_pred)
            test_acc = accuracy_score(y_test, y_test_pred)
            
            if len(target_names) == 2:
                train_f1 = f1_score(y_train, y_train_pred)
                test_f1 = f1_score(y_test, y_test_pred)
            else:
                train_f1 = f1_score(y_train, y_train_pred, average='weighted')
                test_f1 = f1_score(y_test, y_test_pred, average='weighted')
            
            # é¡¯ç¤ºçµæœ
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Train-Data æº–ç¢ºç‡", f"{train_acc:.4f}")
            with col2:
                st.metric("Test-Data æº–ç¢ºç‡", f"{test_acc:.4f}")
            with col3:
                st.metric("Train-Data F1", f"{train_f1:.4f}")
            with col4:
                st.metric("Test-Data F1", f"{test_f1:.4f}")
            
            # æ”¯æŒå‘é‡ä¿¡æ¯
            st.info(f"**æ”¯æŒå‘é‡æ•¸é‡**: {len(model.support_)} / {len(X_train)} ({len(model.support_)/len(X_train)*100:.1f}%)")
            
            # æ··æ·†çŸ©é™£
            st.markdown("### ğŸ“Š æ··æ·†çŸ©é™£")
            
            col1, col2 = st.columns(2)
            
            with col1:
                cm_train = confusion_matrix(y_train, y_train_pred)
                fig = px.imshow(cm_train, 
                               text_auto=True, 
                               x=target_names, 
                               y=target_names,
                               title="Training Data æ··æ·†çŸ©é™£")
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                cm_test = confusion_matrix(y_test, y_test_pred)
                fig = px.imshow(cm_test, 
                               text_auto=True, 
                               x=target_names, 
                               y=target_names,
                               title="Test Data æ··æ·†çŸ©é™£")
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)

elif page == "ğŸ§® è²è‘‰æ–¯åˆ†é¡å™¨":
    st.markdown('<h1 class="main-header">ğŸ§® è²è‘‰æ–¯åˆ†é¡å™¨ (Naive Bayes Classifier)</h1>', unsafe_allow_html=True)
    
    st.markdown("## ğŸ§® æ•¸å­¸åŸç†")
    
    st.markdown("### ğŸ“Š è²è‘‰æ–¯å®šç†")
    st.latex(r'''
    P(y|X) = \frac{P(X|y) \cdot P(y)}{P(X)}
    ''')
    
    st.markdown("### ğŸ”§ æœ´ç´ å‡è¨­")
    st.markdown("å‡è¨­ç‰¹å¾µä¹‹é–“æ¢ä»¶ç¨ç«‹ï¼š")
    
    st.latex(r'''
    P(X|y) = \prod_{i=1}^{n} P(x_i|y)
    ''')
    
    # å„ªç¼ºé»
    col1, col2 = st.columns(2)
    
    with col1:
        st.success("### âœ… å„ªé»")
        st.markdown("""
        - âš¡ **è¨“ç·´å’Œé æ¸¬å¿«é€Ÿ**ï¼šç·šæ€§æ™‚é–“è¤‡é›œåº¦
        - ğŸ“Š **å°æ¨£æœ¬è¡¨ç¾å¥½**ï¼šä¸éœ€è¦å¤§é‡æ•¸æ“š
        - ğŸ¯ **å¤šåˆ†é¡å¤©ç„¶æ”¯æŒ**ï¼šç›´æ¥è¨ˆç®—æ¦‚ç‡
        - ğŸ›¡ï¸ **å°é›¢ç¾¤å€¼ä¸æ•æ„Ÿ**ï¼šåŸºæ–¼æ¦‚ç‡
        - ğŸ’¾ **è¨˜æ†¶é«”éœ€æ±‚å°**ï¼šåªéœ€å­˜å„²çµ±è¨ˆé‡
        """)
    
    with col2:
        st.error("### âŒ ç¼ºé»")
        st.markdown("""
        - ğŸ”— **ç¨ç«‹æ€§å‡è¨­å¼·**ï¼šç‰¹å¾µç›¸é—œæ™‚æ€§èƒ½å·®
        - ğŸ“ˆ **ç·šæ€§æ±ºç­–é‚Šç•Œ**ï¼šç„¡æ³•è™•ç†è¤‡é›œé—œä¿‚
        - ğŸ² **æ¦‚ç‡ä¼°è¨ˆåå·®**ï¼šå¯èƒ½éæ–¼è‡ªä¿¡
        - ğŸ“Š **é€£çºŒç‰¹å¾µéœ€è¦å‡è¨­åˆ†å¸ƒ**ï¼šé€šå¸¸å‡è¨­é«˜æ–¯
        """)
    
    st.markdown("## ğŸ›ï¸ äº’å‹•å¼å¯¦é©—")
    
    X, y, target_names = get_current_data()
    
    if len(X) > 0:
        # åƒæ•¸è¨­ç½®
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**é«˜æ–¯æœ´ç´ è²è‘‰æ–¯åƒæ•¸ï¼š**")
            var_smoothing = st.slider("æ–¹å·®å¹³æ»‘åƒæ•¸ï¼š", 1e-12, 1e-6, 1e-9, 1e-12)
        
        with col2:
            test_size = st.slider("æ¸¬è©¦é›†æ¯”ä¾‹ï¼š", 0.1, 0.5, 0.2, 0.05)
            random_seed = st.slider("éš¨æ©Ÿç¨®å­ï¼š", 1, 100, 42)
        
        # ç‰¹å¾µé¸æ“‡
        selected_features = st.multiselect(
            "é¸æ“‡ç”¨æ–¼å»ºæ¨¡çš„ç‰¹å¾µï¼š",
            X.columns.tolist(),
            default=X.columns.tolist()[:4]
        )
        
        if len(selected_features) > 0:
            X_selected = X[selected_features]
            
            # æ•¸æ“šåˆ†å‰²
            X_train, X_test, y_train, y_test = train_test_split(
                X_selected, y, test_size=test_size, random_state=random_seed
            )
            
            # å»ºç«‹æ¨¡å‹
            model = GaussianNB(var_smoothing=var_smoothing)
            model.fit(X_train, y_train)
            
            # é æ¸¬
            y_train_pred = model.predict(X_train)
            y_test_pred = model.predict(X_test)
            y_train_proba = model.predict_proba(X_train)
            y_test_proba = model.predict_proba(X_test)
            
            # è©•ä¼°æŒ‡æ¨™
            train_acc = accuracy_score(y_train, y_train_pred)
            test_acc = accuracy_score(y_test, y_test_pred)
            
            if len(target_names) == 2:
                train_f1 = f1_score(y_train, y_train_pred)
                test_f1 = f1_score(y_test, y_test_pred)
            else:
                train_f1 = f1_score(y_train, y_train_pred, average='weighted')
                test_f1 = f1_score(y_test, y_test_pred, average='weighted')
            
            # é¡¯ç¤ºçµæœ
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Train-Data æº–ç¢ºç‡", f"{train_acc:.4f}")
            with col2:
                st.metric("Test-Data æº–ç¢ºç‡", f"{test_acc:.4f}")
            with col3:
                st.metric("Train-Data F1", f"{train_f1:.4f}")
            with col4:
                st.metric("Test-Data F1", f"{test_f1:.4f}")
            
            # æ··æ·†çŸ©é™£
            st.markdown("### ğŸ“Š æ··æ·†çŸ©é™£")
            
            col1, col2 = st.columns(2)
            
            with col1:
                cm_train = confusion_matrix(y_train, y_train_pred)
                fig = px.imshow(cm_train, 
                               text_auto=True, 
                               x=target_names, 
                               y=target_names,
                               title="Training Data æ··æ·†çŸ©é™£")
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                cm_test = confusion_matrix(y_test, y_test_pred)
                fig = px.imshow(cm_test, 
                               text_auto=True, 
                               x=target_names, 
                               y=target_names,
                               title="Test Data æ··æ·†çŸ©é™£")
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
            
            # é æ¸¬æ¦‚ç‡åˆ†æ
            st.markdown("### ğŸ“ˆ é æ¸¬æ¦‚ç‡åˆ†æ")
            
            # è¨ˆç®—å¹³å‡é æ¸¬æ¦‚ç‡
            avg_proba = np.mean(y_test_proba, axis=0)
            
            fig = go.Figure(data=[
                go.Bar(x=target_names, y=avg_proba, marker_color='lightblue')
            ])
            fig.update_layout(
                title="å„é¡åˆ¥å¹³å‡é æ¸¬æ¦‚ç‡",
                xaxis_title="é¡åˆ¥",
                yaxis_title="å¹³å‡æ¦‚ç‡",
                height=400
            )
            st.plotly_chart(fig, use_container_width=True)

elif page == "ğŸ§  ç¥ç¶“ç¶²è·¯åˆ†é¡":
    st.markdown('<h1 class="main-header">ğŸ§  ç¥ç¶“ç¶²è·¯åˆ†é¡ (Neural Network Classification)</h1>', unsafe_allow_html=True)
    
    st.markdown("## ğŸ§® æ•¸å­¸åŸç†")
    
    st.markdown("### ğŸ§  å¤šå±¤æ„ŸçŸ¥å™¨ (MLP)")
    st.markdown("ç¥ç¶“ç¶²è·¯é€šéå¤šå±¤éç·šæ€§è®Šæ›å­¸ç¿’è¤‡é›œæ¨¡å¼ï¼š")
    
    st.latex(r'''
    \begin{align}
    z^{(l)} &= W^{(l)} a^{(l-1)} + b^{(l)} \\
    a^{(l)} &= \sigma(z^{(l)})
    \end{align}
    ''')
    
    st.markdown("### ğŸ“Š æ¿€æ´»å‡½æ•¸")
    st.latex(r'''
    \begin{align}
    \text{ReLUï¼š} \sigma(x) &= \max(0, x) \\
    \text{Sigmoidï¼š} \sigma(x) &= \frac{1}{1 + e^{-x}} \\
    \text{Tanhï¼š} \sigma(x) &= \frac{e^x - e^{-x}}{e^x + e^{-x}}
    \end{align}
    ''')
    
    # å„ªç¼ºé»
    col1, col2 = st.columns(2)
    
    with col1:
        st.success("### âœ… å„ªé»")
        st.markdown("""
        - ğŸŒŠ **å­¸ç¿’éç·šæ€§é—œä¿‚**ï¼šè¤‡é›œæ±ºç­–é‚Šç•Œ
        - ğŸ¯ **é€šç”¨è¿‘ä¼¼å™¨**ï¼šç†è«–ä¸Šå¯æ“¬åˆä»»ä½•å‡½æ•¸
        - ğŸ”§ **è‡ªå‹•ç‰¹å¾µå­¸ç¿’**ï¼šéš±è—å±¤æå–ç‰¹å¾µ
        - ğŸ“Š **é©æ‡‰æ€§å¼·**ï¼šé©ç”¨å„ç¨®å•é¡Œ
        """)
    
    with col2:
        st.error("### âŒ ç¼ºé»")
        st.markdown("""
        - â±ï¸ **è¨“ç·´æ™‚é–“é•·**ï¼šè¿­ä»£å„ªåŒ–éç¨‹
        - ğŸ›ï¸ **è¶…åƒæ•¸å¤š**ï¼šéœ€è¦ä»”ç´°èª¿åƒ
        - ğŸ” **é»‘ç›’æ¨¡å‹**ï¼šé›£ä»¥è§£é‡‹
        - ğŸ“Š **éœ€è¦å¤§é‡æ•¸æ“š**ï¼šé¿å…éæ“¬åˆ
        """)
    
    st.markdown("## ğŸ›ï¸ äº’å‹•å¼å¯¦é©—")
    
    X, y, target_names = get_current_data()
    
    if len(X) > 0:
        # åƒæ•¸è¨­ç½®
        col1, col2 = st.columns(2)
        
        with col1:
            hidden_layer_sizes = st.selectbox("éš±è—å±¤çµæ§‹ï¼š", [
                (50,), (100,), (50, 50), (100, 50), (100, 100)
            ])
            activation = st.selectbox("æ¿€æ´»å‡½æ•¸ï¼š", ["relu", "tanh", "logistic"])
        
        with col2:
            learning_rate_init = st.slider("åˆå§‹å­¸ç¿’ç‡ï¼š", 0.001, 0.1, 0.001, 0.001)
            max_iter = st.slider("æœ€å¤§è¿­ä»£æ¬¡æ•¸ï¼š", 100, 1000, 200, 100)
        
        # ç‰¹å¾µé¸æ“‡
        selected_features = st.multiselect(
            "é¸æ“‡ç”¨æ–¼å»ºæ¨¡çš„ç‰¹å¾µï¼š",
            X.columns.tolist(),
            default=X.columns.tolist()[:6]
        )
        
        if len(selected_features) > 0:
            X_selected = X[selected_features]
            
            # æ•¸æ“šåˆ†å‰²
            X_train, X_test, y_train, y_test = train_test_split(
                X_selected, y, test_size=0.2, random_state=42
            )
            
            # æ¨™æº–åŒ–ï¼ˆç¥ç¶“ç¶²è·¯å¿…é ˆæ¨™æº–åŒ–ï¼‰
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # å»ºç«‹æ¨¡å‹
            model = MLPClassifier(
                hidden_layer_sizes=hidden_layer_sizes,
                activation=activation,
                learning_rate_init=learning_rate_init,
                max_iter=max_iter,
                random_state=42
            )
            
            with st.spinner('è¨“ç·´ç¥ç¶“ç¶²è·¯æ¨¡å‹ä¸­...'):
                model.fit(X_train_scaled, y_train)
            
            # é æ¸¬
            y_train_pred = model.predict(X_train_scaled)
            y_test_pred = model.predict(X_test_scaled)
            
            # è©•ä¼°æŒ‡æ¨™
            train_acc = accuracy_score(y_train, y_train_pred)
            test_acc = accuracy_score(y_test, y_test_pred)
            
            if len(target_names) == 2:
                train_f1 = f1_score(y_train, y_train_pred)
                test_f1 = f1_score(y_test, y_test_pred)
            else:
                train_f1 = f1_score(y_train, y_train_pred, average='weighted')
                test_f1 = f1_score(y_test, y_test_pred, average='weighted')
            
            # é¡¯ç¤ºçµæœ
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Train-Data æº–ç¢ºç‡", f"{train_acc:.4f}")
            with col2:
                st.metric("Test-Data æº–ç¢ºç‡", f"{test_acc:.4f}")
            with col3:
                st.metric("Train-Data F1", f"{train_f1:.4f}")
            with col4:
                st.metric("Test-Data F1", f"{test_f1:.4f}")
            
            # æ¨¡å‹æ”¶æ–‚ä¿¡æ¯
            if hasattr(model, 'n_iter_'):
                st.info(f"**æ”¶æ–‚ä¿¡æ¯**: è¿­ä»£{model.n_iter_}æ¬¡å¾Œæ”¶æ–‚")
            
            # æ··æ·†çŸ©é™£
            st.markdown("### ğŸ“Š æ··æ·†çŸ©é™£")
            
            col1, col2 = st.columns(2)
            
            with col1:
                cm_train = confusion_matrix(y_train, y_train_pred)
                fig = px.imshow(cm_train, 
                               text_auto=True, 
                               x=target_names, 
                               y=target_names,
                               title="Training Data æ··æ·†çŸ©é™£")
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                cm_test = confusion_matrix(y_test, y_test_pred)
                fig = px.imshow(cm_test, 
                               text_auto=True, 
                               x=target_names, 
                               y=target_names,
                               title="Test Data æ··æ·†çŸ©é™£")
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
            
            # æå¤±æ›²ç·š
            if hasattr(model, 'loss_curve_'):
                st.markdown("### ğŸ“ˆ æå¤±æ›²ç·š")
                
                fig = go.Figure()
                fig.add_trace(go.Scatter(
                    x=list(range(1, len(model.loss_curve_)+1)), 
                    y=model.loss_curve_,
                    mode='lines',
                    name='Training Loss'
                ))
                fig.update_layout(
                    title="ç¥ç¶“ç¶²è·¯è¨“ç·´æå¤±æ›²ç·š",
                    xaxis_title="è¿­ä»£æ¬¡æ•¸",
                    yaxis_title="æå¤±å€¼",
                    height=400
                )
                st.plotly_chart(fig, use_container_width=True)

elif page == "ğŸ”„ äº¤å‰é©—è­‰èˆ‡ç©©å®šæ€§":
    st.markdown('<h1 class="main-header">ğŸ”„ äº¤å‰é©—è­‰èˆ‡ç©©å®šæ€§åˆ†æ</h1>', unsafe_allow_html=True)
    
    st.markdown("## ğŸ”„ äº¤å‰é©—è­‰åŸç†")
    
    st.markdown("### ğŸ“Š KæŠ˜äº¤å‰é©—è­‰")
    st.markdown("å°‡æ•¸æ“šåˆ†æˆKå€‹å­é›†ï¼Œè¼ªæµä½œç‚ºæ¸¬è©¦é›†ï¼š")
    
    st.latex(r'''
    CV_{score} = \frac{1}{K} \sum_{i=1}^{K} Score_i
    ''')
    
    st.markdown("### ğŸ¯ äº¤å‰é©—è­‰çš„å„ªé»")
    st.info("""
    - ğŸ¯ **æ›´å¯é çš„è©•ä¼°**ï¼šä½¿ç”¨æ‰€æœ‰æ•¸æ“šé€²è¡Œé©—è­‰
    - ğŸ“Š **ç©©å®šæ€§æ¸¬è©¦**ï¼šè§€å¯Ÿæ€§èƒ½è®ŠåŒ–
    - ğŸ”§ **æ¸›å°‘éæ“¬åˆé¢¨éšª**ï¼šå¤šæ¬¡é©—è­‰
    - ğŸ“ˆ **ç½®ä¿¡å€é–“**ï¼šæä¾›æ€§èƒ½ç¯„åœ
    """)
    
    X, y, target_names = get_current_data()
    
    if len(X) > 0:
        # åƒæ•¸è¨­ç½®
        col1, col2 = st.columns(2)
        
        with col1:
            cv_folds = st.slider("äº¤å‰é©—è­‰æŠ˜æ•¸ï¼š", 3, 10, 5)
            model_choice = st.selectbox("é¸æ“‡æ¨¡å‹ï¼š", [
                "é‚è¼¯å›æ­¸", "éš¨æ©Ÿæ£®æ—", "æ”¯æŒå‘é‡æ©Ÿ", "Kè¿‘é„°"
            ])
        
        with col2:
            test_size = st.slider("æœ€çµ‚æ¸¬è©¦é›†æ¯”ä¾‹ï¼š", 0.1, 0.3, 0.2, 0.05)
            random_seed = st.slider("éš¨æ©Ÿç¨®å­ï¼š", 1, 100, 42)
        
        # ç‰¹å¾µé¸æ“‡
        selected_features = st.multiselect(
            "é¸æ“‡ç”¨æ–¼å»ºæ¨¡çš„ç‰¹å¾µï¼š",
            X.columns.tolist(),
            default=X.columns.tolist()[:6]
        )
        
        if len(selected_features) > 0:
            X_selected = X[selected_features]
            
            # æ•¸æ“šåˆ†å‰²
            X_train, X_test, y_train, y_test = train_test_split(
                X_selected, y, test_size=test_size, random_state=random_seed
            )
            
            # æ¨™æº–åŒ–
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # é¸æ“‡æ¨¡å‹
            if model_choice == "é‚è¼¯å›æ­¸":
                model = LogisticRegression(random_state=random_seed, max_iter=1000)
            elif model_choice == "éš¨æ©Ÿæ£®æ—":
                model = RandomForestClassifier(n_estimators=100, random_state=random_seed)
            elif model_choice == "æ”¯æŒå‘é‡æ©Ÿ":
                model = SVC(random_state=random_seed)
            else:  # Kè¿‘é„°
                model = KNeighborsClassifier(n_neighbors=5)
            
            # äº¤å‰é©—è­‰
            with st.spinner('åŸ·è¡Œäº¤å‰é©—è­‰ä¸­...'):
                cv_scores = cross_val_score(
                    model, X_train_scaled, y_train, 
                    cv=cv_folds, scoring='accuracy'
                )
            
            # æœ€çµ‚æ¨¡å‹è¨“ç·´
            model.fit(X_train_scaled, y_train)
            final_score = model.score(X_test_scaled, y_test)
            
            # çµæœé¡¯ç¤º
            st.markdown("### ğŸ“Š äº¤å‰é©—è­‰çµæœ")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("CVå¹³å‡åˆ†æ•¸", f"{cv_scores.mean():.4f}")
            with col2:
                st.metric("CVæ¨™æº–å·®", f"{cv_scores.std():.4f}")
            with col3:
                st.metric("æœ€çµ‚æ¸¬è©¦åˆ†æ•¸", f"{final_score:.4f}")
            with col4:
                st.metric("ç©©å®šæ€§è©•ç´š", 
                         "å„ªç§€" if cv_scores.std() < 0.02 else 
                         "è‰¯å¥½" if cv_scores.std() < 0.05 else "ä¸€èˆ¬")
            
            # äº¤å‰é©—è­‰åˆ†æ•¸åˆ†å¸ƒ
            st.markdown("### ğŸ“ˆ äº¤å‰é©—è­‰åˆ†æ•¸åˆ†å¸ƒ")
            
            fig = go.Figure()
            
            # ç®±ç·šåœ–
            fig.add_trace(go.Box(
                y=cv_scores,
                name='CV Scores',
                boxpoints='all',
                jitter=0.3,
                pointpos=-1.8
            ))
            
            # æ·»åŠ æœ€çµ‚æ¸¬è©¦åˆ†æ•¸ç·š
            fig.add_hline(y=final_score, line_dash="dash", line_color="red",
                         annotation_text=f"æœ€çµ‚æ¸¬è©¦åˆ†æ•¸: {final_score:.4f}")
            
            fig.update_layout(
                title=f"{model_choice} - {cv_folds}æŠ˜äº¤å‰é©—è­‰åˆ†æ•¸åˆ†å¸ƒ",
                yaxis_title="æº–ç¢ºç‡",
                height=400
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # ç©©å®šæ€§åˆ†æ
            st.markdown("### ğŸ” ç©©å®šæ€§åˆ†æ")
            
            stability_score = 1 - (cv_scores.std() / cv_scores.mean())
            
            if stability_score > 0.95:
                st.success(f"ğŸ¯ **æ¨¡å‹ç©©å®šæ€§å„ªç§€** (ç©©å®šæ€§æŒ‡æ¨™: {stability_score:.3f})")
            elif stability_score > 0.90:
                st.info(f"âœ… **æ¨¡å‹ç©©å®šæ€§è‰¯å¥½** (ç©©å®šæ€§æŒ‡æ¨™: {stability_score:.3f})")
            else:
                st.warning(f"âš ï¸ **æ¨¡å‹ç©©å®šæ€§ä¸€èˆ¬** (ç©©å®šæ€§æŒ‡æ¨™: {stability_score:.3f})")

elif page == "âš–ï¸ è³‡æ–™ä¸å¹³è¡¡è™•ç†":
    st.markdown('<h1 class="main-header">âš–ï¸ è³‡æ–™ä¸å¹³è¡¡è™•ç†</h1>', unsafe_allow_html=True)
    
    st.markdown("## âš–ï¸ è³‡æ–™ä¸å¹³è¡¡å•é¡Œ")
    
    st.markdown("### ğŸ¯ ä»€éº¼æ˜¯è³‡æ–™ä¸å¹³è¡¡")
    st.markdown("ç•¶ä¸åŒé¡åˆ¥çš„æ¨£æœ¬æ•¸é‡å·®ç•°å¾ˆå¤§æ™‚ï¼Œæœƒå°è‡´æ¨¡å‹åå‘å¤šæ•¸é¡åˆ¥ã€‚")
    
    st.markdown("### ğŸ“Š å¸¸è¦‹è™•ç†æ–¹æ³•")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### ğŸ”§ æ•¸æ“šå±¤é¢")
        st.markdown("""
        - **éæ¡æ¨£ (Over-sampling)**ï¼šå¢åŠ å°‘æ•¸é¡åˆ¥æ¨£æœ¬
        - **æ¬ æ¡æ¨£ (Under-sampling)**ï¼šæ¸›å°‘å¤šæ•¸é¡åˆ¥æ¨£æœ¬  
        - **SMOTE**ï¼šåˆæˆå°‘æ•¸é¡åˆ¥æ¨£æœ¬
        - **çµ„åˆæ¡æ¨£**ï¼šçµåˆéæ¡æ¨£å’Œæ¬ æ¡æ¨£
        """)
    
    with col2:
        st.markdown("#### ğŸ›ï¸ ç®—æ³•å±¤é¢")
        st.markdown("""
        - **é¡åˆ¥æ¬Šé‡**ï¼šçµ¦å°‘æ•¸é¡åˆ¥æ›´é«˜æ¬Šé‡
        - **é›†æˆæ–¹æ³•**ï¼šBalanced Random Forest
        - **é–¾å€¼èª¿æ•´**ï¼šå„ªåŒ–åˆ†é¡é–¾å€¼
        - **ä»£åƒ¹æ•æ„Ÿå­¸ç¿’**ï¼šä¸åŒéŒ¯èª¤ä¸åŒä»£åƒ¹
        """)
    
    X, y, target_names = get_current_data()
    
    if len(X) > 0:
        # æª¢æŸ¥ç•¶å‰æ•¸æ“šé›†çš„å¹³è¡¡æ€§
        class_counts = pd.Series(y).value_counts().sort_index()
        imbalance_ratio = class_counts.min() / class_counts.max()
        
        st.markdown("### ğŸ“Š ç•¶å‰æ•¸æ“šé›†å¹³è¡¡æ€§åˆ†æ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("ä¸å¹³è¡¡æ¯”ä¾‹", f"{imbalance_ratio:.3f}")
            
            if imbalance_ratio < 0.1:
                st.error("åš´é‡ä¸å¹³è¡¡")
            elif imbalance_ratio < 0.5:
                st.warning("ä¸­åº¦ä¸å¹³è¡¡")
            else:
                st.success("ç›¸å°å¹³è¡¡")
        
        with col2:
            # é¡åˆ¥åˆ†å¸ƒåœ–
            fig = go.Figure(data=[
                go.Bar(x=target_names, y=class_counts.values)
            ])
            fig.update_layout(
                title="é¡åˆ¥åˆ†å¸ƒ",
                height=300
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # è™•ç†æ–¹æ³•é¸æ“‡
        st.markdown("### ğŸ”§ ä¸å¹³è¡¡è™•ç†æ–¹æ³•æ¯”è¼ƒ")
        
        processing_method = st.selectbox("é¸æ“‡è™•ç†æ–¹æ³•ï¼š", [
            "ç„¡è™•ç†", "SMOTEéæ¡æ¨£", "é¡åˆ¥æ¬Šé‡å¹³è¡¡"
        ])
        
        # ç‰¹å¾µé¸æ“‡
        selected_features = st.multiselect(
            "é¸æ“‡ç”¨æ–¼å»ºæ¨¡çš„ç‰¹å¾µï¼š",
            X.columns.tolist(),
            default=X.columns.tolist()[:4]
        )
        
        if len(selected_features) > 0:
            X_selected = X[selected_features]
            
            # æ•¸æ“šåˆ†å‰²
            X_train, X_test, y_train, y_test = train_test_split(
                X_selected, y, test_size=0.2, random_state=42
            )
            
            # æ¨™æº–åŒ–
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # æ‡‰ç”¨è™•ç†æ–¹æ³•
            if processing_method == "SMOTEéæ¡æ¨£":
                try:
                    smote = SMOTE(random_state=42)
                    X_train_processed, y_train_processed = smote.fit_resample(X_train_scaled, y_train)
                    st.success("âœ… SMOTEéæ¡æ¨£å®Œæˆ")
                except:
                    X_train_processed, y_train_processed = X_train_scaled, y_train
                    st.error("âŒ SMOTEå¤±æ•—ï¼Œä½¿ç”¨åŸå§‹æ•¸æ“š")
            else:
                X_train_processed, y_train_processed = X_train_scaled, y_train
            
            # å»ºç«‹æ¨¡å‹
            if processing_method == "é¡åˆ¥æ¬Šé‡å¹³è¡¡":
                model = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)
            else:
                model = LogisticRegression(random_state=42, max_iter=1000)
            
            # è¨“ç·´å’Œé æ¸¬
            model.fit(X_train_processed, y_train_processed)
            y_pred = model.predict(X_test_scaled)
            
            # è©•ä¼°
            accuracy = accuracy_score(y_test, y_pred)
            
            if len(target_names) == 2:
                precision = precision_score(y_test, y_pred)
                recall = recall_score(y_test, y_pred)
                f1 = f1_score(y_test, y_pred)
            else:
                precision = precision_score(y_test, y_pred, average='weighted')
                recall = recall_score(y_test, y_pred, average='weighted')
                f1 = f1_score(y_test, y_pred, average='weighted')
            
            # çµæœé¡¯ç¤º
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("æº–ç¢ºç‡", f"{accuracy:.4f}")
            with col2:
                st.metric("ç²¾ç¢ºç‡", f"{precision:.4f}")
            with col3:
                st.metric("å¬å›ç‡", f"{recall:.4f}")
            with col4:
                st.metric("F1åˆ†æ•¸", f"{f1:.4f}")
            
            # æ··æ·†çŸ©é™£
            st.markdown("### ğŸ“Š è™•ç†å¾Œçš„æ··æ·†çŸ©é™£")
            
            cm = confusion_matrix(y_test, y_pred)
            fig = px.imshow(cm, 
                           text_auto=True, 
                           x=target_names, 
                           y=target_names,
                           title=f"æ··æ·†çŸ©é™£ - {processing_method}")
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)

elif page == "ğŸ” æ¨¡å‹å¯è§£é‡‹æ€§":
    st.markdown('<h1 class="main-header">ğŸ” æ¨¡å‹å¯è§£é‡‹æ€§åˆ†æ</h1>', unsafe_allow_html=True)
    
    st.markdown("## ğŸ” ç‚ºä»€éº¼éœ€è¦å¯è§£é‡‹æ€§")
    
    st.info("""
    **æ¨¡å‹å¯è§£é‡‹æ€§çš„é‡è¦æ€§ï¼š**
    - ğŸ¥ **é†«ç™‚è¨ºæ–·**ï¼šé†«ç”Ÿéœ€è¦äº†è§£è¨ºæ–·ä¾æ“š
    - ğŸ¦ **é‡‘èé¢¨æ§**ï¼šç›£ç®¡è¦æ±‚è§£é‡‹æ±ºç­–éç¨‹
    - ğŸ¯ **æ¥­å‹™æ±ºç­–**ï¼šç®¡ç†å±¤éœ€è¦ç†è§£æ¨¡å‹é‚è¼¯
    - ğŸ”§ **æ¨¡å‹æ”¹é€²**ï¼šæ‰¾å‡ºæ¨¡å‹çš„ä¸è¶³ä¹‹è™•
    """)
    
    st.markdown("### ğŸ“Š å¯è§£é‡‹æ€§æ–¹æ³•åˆ†é¡")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### ğŸ” å…§åœ¨å¯è§£é‡‹æ€§")
        st.markdown("""
        - **ç·šæ€§æ¨¡å‹**ï¼šä¿‚æ•¸ç›´æ¥åæ˜ ç‰¹å¾µé‡è¦æ€§
        - **æ±ºç­–æ¨¹**ï¼šè¦å‰‡è·¯å¾‘æ¸…æ™°å¯è¦‹
        - **è²è‘‰æ–¯æ¨¡å‹**ï¼šæ¦‚ç‡æ¨ç†éç¨‹é€æ˜
        """)
    
    with col2:
        st.markdown("#### ğŸ”§ å¾Œè™•ç†å¯è§£é‡‹æ€§")
        st.markdown("""
        - **ç‰¹å¾µé‡è¦æ€§**ï¼šæ’åºç‰¹å¾µè²¢ç»åº¦
        - **LIME**ï¼šå±€éƒ¨ç·šæ€§è¿‘ä¼¼
        - **SHAP**ï¼šåšå¼ˆè«–è§£é‡‹
        """)
    
    X, y, target_names = get_current_data()
    
    if len(X) > 0:
        # æ¨¡å‹é¸æ“‡
        interpretable_model = st.selectbox("é¸æ“‡å¯è§£é‡‹æ¨¡å‹ï¼š", [
            "é‚è¼¯å›æ­¸", "æ±ºç­–æ¨¹", "éš¨æ©Ÿæ£®æ—"
        ])
        
        # ç‰¹å¾µé¸æ“‡
        selected_features = st.multiselect(
            "é¸æ“‡ç”¨æ–¼å»ºæ¨¡çš„ç‰¹å¾µï¼š",
            X.columns.tolist(),
            default=X.columns.tolist()[:6]
        )
        
        if len(selected_features) > 0:
            X_selected = X[selected_features]
            
            # æ•¸æ“šåˆ†å‰²
            X_train, X_test, y_train, y_test = train_test_split(
                X_selected, y, test_size=0.2, random_state=42
            )
            
            # æ¨™æº–åŒ–
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # å»ºç«‹æ¨¡å‹
            if interpretable_model == "é‚è¼¯å›æ­¸":
                model = LogisticRegression(random_state=42, max_iter=1000)
                model.fit(X_train_scaled, y_train)
            elif interpretable_model == "æ±ºç­–æ¨¹":
                model = DecisionTreeClassifier(max_depth=5, random_state=42)
                model.fit(X_train, y_train)  # æ±ºç­–æ¨¹ä¸éœ€è¦æ¨™æº–åŒ–
            else:  # éš¨æ©Ÿæ£®æ—
                model = RandomForestClassifier(n_estimators=100, random_state=42)
                model.fit(X_train, y_train)  # éš¨æ©Ÿæ£®æ—ä¸éœ€è¦æ¨™æº–åŒ–
            
            # é æ¸¬
            if interpretable_model == "é‚è¼¯å›æ­¸":
                y_pred = model.predict(X_test_scaled)
                accuracy = model.score(X_test_scaled, y_test)
            else:
                y_pred = model.predict(X_test)
                accuracy = model.score(X_test, y_test)
            
            st.metric("æ¨¡å‹æº–ç¢ºç‡", f"{accuracy:.4f}")
            
            # å¯è§£é‡‹æ€§åˆ†æ
            st.markdown("### ğŸ” æ¨¡å‹å¯è§£é‡‹æ€§åˆ†æ")
            
            if interpretable_model == "é‚è¼¯å›æ­¸":
                # é‚è¼¯å›æ­¸ä¿‚æ•¸åˆ†æ
                if len(target_names) == 2:  # äºŒåˆ†é¡
                    coef_df = pd.DataFrame({
                        'ç‰¹å¾µ': selected_features,
                        'ä¿‚æ•¸': model.coef_[0],
                        'çµ•å°å€¼': np.abs(model.coef_[0])
                    }).sort_values('çµ•å°å€¼', ascending=False)
                    
                    fig = go.Figure(data=[
                        go.Bar(x=coef_df['ç‰¹å¾µ'], y=coef_df['ä¿‚æ•¸'],
                               marker_color=['red' if x < 0 else 'blue' for x in coef_df['ä¿‚æ•¸']])
                    ])
                    fig.update_layout(
                        title="é‚è¼¯å›æ­¸ç‰¹å¾µä¿‚æ•¸ (æ­£æ•¸å¢åŠ æ­£é¡æ¦‚ç‡ï¼Œè² æ•¸æ¸›å°‘)",
                        xaxis_title="ç‰¹å¾µ",
                        yaxis_title="ä¿‚æ•¸å€¼",
                        xaxis_tickangle=45
                    )
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # ä¿‚æ•¸è§£é‡‹
                    st.markdown("#### ğŸ“Š ä¿‚æ•¸è§£é‡‹")
                    for _, row in coef_df.head(3).iterrows():
                        if row['ä¿‚æ•¸'] > 0:
                            st.success(f"**{row['ç‰¹å¾µ']}**: ä¿‚æ•¸ {row['ä¿‚æ•¸']:.3f} - å¢åŠ æ­¤ç‰¹å¾µæœƒæé«˜æ­£é¡æ¦‚ç‡")
                        else:
                            st.error(f"**{row['ç‰¹å¾µ']}**: ä¿‚æ•¸ {row['ä¿‚æ•¸']:.3f} - å¢åŠ æ­¤ç‰¹å¾µæœƒé™ä½æ­£é¡æ¦‚ç‡")
            
            elif interpretable_model in ["æ±ºç­–æ¨¹", "éš¨æ©Ÿæ£®æ—"]:
                # ç‰¹å¾µé‡è¦æ€§åˆ†æ
                feature_importance = pd.DataFrame({
                    'ç‰¹å¾µ': selected_features,
                    'é‡è¦æ€§': model.feature_importances_
                }).sort_values('é‡è¦æ€§', ascending=False)
                
                fig = go.Figure(data=[
                    go.Bar(x=feature_importance['ç‰¹å¾µ'], y=feature_importance['é‡è¦æ€§'],
                           marker_color='green')
                ])
                fig.update_layout(
                    title=f"{interpretable_model}ç‰¹å¾µé‡è¦æ€§",
                    xaxis_title="ç‰¹å¾µ",
                    yaxis_title="é‡è¦æ€§",
                    xaxis_tickangle=45
                )
                st.plotly_chart(fig, use_container_width=True)
                
                # é‡è¦æ€§è§£é‡‹
                st.markdown("#### ğŸ“Š ç‰¹å¾µé‡è¦æ€§è§£é‡‹")
                for _, row in feature_importance.head(3).iterrows():
                    st.info(f"**{row['ç‰¹å¾µ']}**: é‡è¦æ€§ {row['é‡è¦æ€§']:.3f} - å°åˆ†é¡æ±ºç­–çš„è²¢ç»åº¦")
            
            # é æ¸¬ç¤ºä¾‹è§£é‡‹
            st.markdown("### ğŸ¯ å–®å€‹é æ¸¬ç¤ºä¾‹è§£é‡‹")
            
            sample_idx = st.slider("é¸æ“‡æ¸¬è©¦æ¨£æœ¬ï¼š", 0, len(X_test)-1, 0)
            
            if interpretable_model == "é‚è¼¯å›æ­¸":
                sample_features = X_test_scaled[sample_idx]
                sample_pred_proba = model.predict_proba([sample_features])[0]
            else:
                sample_features = X_test.iloc[sample_idx].values
                sample_pred_proba = model.predict_proba([sample_features])[0]
            
            sample_pred = np.argmax(sample_pred_proba)
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### ğŸ“Š æ¨£æœ¬ç‰¹å¾µå€¼")
                for i, feature in enumerate(selected_features):
                    st.metric(feature, f"{X_test.iloc[sample_idx][feature]:.3f}")
            
            with col2:
                st.markdown("#### ğŸ¯ é æ¸¬çµæœ")
                st.metric("é æ¸¬é¡åˆ¥", target_names[sample_pred])
                st.metric("é æ¸¬æ¦‚ç‡", f"{sample_pred_proba[sample_pred]:.3f}")
                
                # æ¦‚ç‡åˆ†å¸ƒ
                fig = go.Figure(data=[
                    go.Bar(x=target_names, y=sample_pred_proba)
                ])
                fig.update_layout(
                    title="å„é¡åˆ¥é æ¸¬æ¦‚ç‡",
                    height=300
                )
                st.plotly_chart(fig, use_container_width=True)

elif page == "ğŸ† æ¨¡å‹ç¶œåˆæ¯”è¼ƒ":
    st.markdown('<h1 class="main-header">ğŸ† æ¨¡å‹ç¶œåˆæ¯”è¼ƒ</h1>', unsafe_allow_html=True)
    
    st.markdown("## ğŸ† å¤šæ¨¡å‹æ€§èƒ½æ¯”è¼ƒ")
    
    st.info("ğŸ’¡ æœ¬é é¢å°‡è¨“ç·´å¤šå€‹åˆ†é¡æ¨¡å‹ä¸¦é€²è¡Œå…¨é¢æ¯”è¼ƒï¼Œå¹«åŠ©æ‚¨é¸æ“‡æœ€é©åˆçš„æ¨¡å‹ã€‚")
    
    X, y, target_names = get_current_data()
    
    if len(X) > 0:
        # åƒæ•¸è¨­ç½®
        col1, col2 = st.columns(2)
        
        with col1:
            test_size = st.slider("æ¸¬è©¦é›†æ¯”ä¾‹ï¼š", 0.1, 0.4, 0.2, 0.05)
            cv_folds = st.slider("äº¤å‰é©—è­‰æŠ˜æ•¸ï¼š", 3, 10, 5)
        
        with col2:
            random_seed = st.slider("éš¨æ©Ÿç¨®å­ï¼š", 1, 100, 42)
            
        # ç‰¹å¾µé¸æ“‡
        selected_features = st.multiselect(
            "é¸æ“‡ç”¨æ–¼å»ºæ¨¡çš„ç‰¹å¾µï¼š",
            X.columns.tolist(),
            default=X.columns.tolist()
        )
        
        if len(selected_features) > 0:
            X_selected = X[selected_features]
            
            # æ•¸æ“šåˆ†å‰²
            X_train, X_test, y_train, y_test = train_test_split(
                X_selected, y, test_size=test_size, random_state=random_seed
            )
            
            # æ¨™æº–åŒ–
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # å®šç¾©æ¨¡å‹
            models = {
                'é‚è¼¯å›æ­¸': LogisticRegression(random_state=random_seed, max_iter=1000),
                'Kè¿‘é„°': KNeighborsClassifier(n_neighbors=5),
                'æ±ºç­–æ¨¹': DecisionTreeClassifier(random_state=random_seed, max_depth=10),
                'éš¨æ©Ÿæ£®æ—': RandomForestClassifier(n_estimators=100, random_state=random_seed),
                'æ¢¯åº¦æå‡': GradientBoostingClassifier(n_estimators=100, random_state=random_seed),
                'æ”¯æŒå‘é‡æ©Ÿ': SVC(random_state=random_seed, probability=True),
                'è²è‘‰æ–¯åˆ†é¡å™¨': GaussianNB(),
                'ç¥ç¶“ç¶²è·¯': MLPClassifier(hidden_layer_sizes=(100,), random_state=random_seed, max_iter=500)
            }
            
            # è¨“ç·´å’Œè©•ä¼°
            results = {}
            
            with st.spinner('è¨“ç·´å¤šå€‹æ¨¡å‹ä¸­...'):
                for name, model in models.items():
                    # é¸æ“‡æ˜¯å¦éœ€è¦æ¨™æº–åŒ–
                    if name in ['é‚è¼¯å›æ­¸', 'Kè¿‘é„°', 'æ”¯æŒå‘é‡æ©Ÿ', 'è²è‘‰æ–¯åˆ†é¡å™¨', 'ç¥ç¶“ç¶²è·¯']:
                        X_train_use = X_train_scaled
                        X_test_use = X_test_scaled
                    else:  # æ±ºç­–æ¨¹ã€éš¨æ©Ÿæ£®æ—ã€æ¢¯åº¦æå‡ä¸éœ€è¦æ¨™æº–åŒ–
                        X_train_use = X_train
                        X_test_use = X_test
                    
                    # è¨“ç·´æ¨¡å‹
                    model.fit(X_train_use, y_train)
                    
                    # é æ¸¬
                    y_pred = model.predict(X_test_use)
                    
                    # è©•ä¼°æŒ‡æ¨™
                    accuracy = accuracy_score(y_test, y_pred)
                    
                    if len(target_names) == 2:
                        precision = precision_score(y_test, y_pred)
                        recall = recall_score(y_test, y_pred)
                        f1 = f1_score(y_test, y_pred)
                    else:
                        precision = precision_score(y_test, y_pred, average='weighted')
                        recall = recall_score(y_test, y_pred, average='weighted')
                        f1 = f1_score(y_test, y_pred, average='weighted')
                    
                    # äº¤å‰é©—è­‰
                    cv_scores = cross_val_score(model, X_train_use, y_train, cv=cv_folds, scoring='accuracy')
                    
                    results[name] = {
                        'accuracy': accuracy,
                        'precision': precision,
                        'recall': recall,
                        'f1': f1,
                        'cv_mean': cv_scores.mean(),
                        'cv_std': cv_scores.std()
                    }
            
            # çµæœå±•ç¤º
            st.markdown("### ğŸ“Š æ¨¡å‹æ€§èƒ½æ¯”è¼ƒè¡¨")
            
            results_df = pd.DataFrame(results).T
            results_df = results_df.round(4)
            
            # æ·»åŠ æ’å
            results_df['F1æ’å'] = results_df['f1'].rank(ascending=False).astype(int)
            results_df['æº–ç¢ºç‡æ’å'] = results_df['accuracy'].rank(ascending=False).astype(int)
            
            st.dataframe(results_df, use_container_width=True)
            
            # æ€§èƒ½æ¯”è¼ƒåœ–
            st.markdown("### ğŸ“ˆ æ¨¡å‹æ€§èƒ½å¯è¦–åŒ–æ¯”è¼ƒ")
            
            # æº–ç¢ºç‡æ¯”è¼ƒ
            fig = go.Figure()
            
            fig.add_trace(go.Bar(
                name='æ¸¬è©¦æº–ç¢ºç‡',
                x=list(results.keys()),
                y=[results[name]['accuracy'] for name in results.keys()],
                marker_color='lightblue'
            ))
            
            fig.add_trace(go.Bar(
                name='CVå¹³å‡æº–ç¢ºç‡',
                x=list(results.keys()),
                y=[results[name]['cv_mean'] for name in results.keys()],
                marker_color='lightcoral'
            ))
            
            fig.update_layout(
                title="æ¨¡å‹æº–ç¢ºç‡æ¯”è¼ƒ",
                xaxis_title="æ¨¡å‹",
                yaxis_title="æº–ç¢ºç‡",
                barmode='group',
                height=400
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # F1åˆ†æ•¸æ¯”è¼ƒ
            fig = go.Figure(data=[
                go.Bar(x=list(results.keys()), 
                       y=[results[name]['f1'] for name in results.keys()],
                       marker_color='lightgreen')
            ])
            fig.update_layout(
                title="æ¨¡å‹F1åˆ†æ•¸æ¯”è¼ƒ",
                xaxis_title="æ¨¡å‹",
                yaxis_title="F1åˆ†æ•¸",
                height=400
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # æ¨¡å‹æ¨è–¦
            st.markdown("### ğŸ¯ æ¨¡å‹é¸æ“‡å»ºè­°")
            
            best_f1_model = max(results.keys(), key=lambda x: results[x]['f1'])
            best_acc_model = max(results.keys(), key=lambda x: results[x]['accuracy'])
            most_stable_model = min(results.keys(), key=lambda x: results[x]['cv_std'])
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.success(f"""
                **ğŸ† æœ€ä½³F1åˆ†æ•¸**
                
                **{best_f1_model}**
                
                F1: {results[best_f1_model]['f1']:.4f}
                """)
            
            with col2:
                st.info(f"""
                **ğŸ¯ æœ€ä½³æº–ç¢ºç‡**
                
                **{best_acc_model}**
                
                æº–ç¢ºç‡: {results[best_acc_model]['accuracy']:.4f}
                """)
            
            with col3:
                st.warning(f"""
                **âš–ï¸ æœ€ç©©å®šæ¨¡å‹**
                
                **{most_stable_model}**
                
                CVæ¨™æº–å·®: {results[most_stable_model]['cv_std']:.4f}
                """)
            
            # é¸æ“‡å»ºè­°
            st.markdown("### ğŸ’¡ é¸æ“‡å»ºè­°")
            
            if results[best_f1_model]['f1'] > 0.9:
                st.success("ğŸ‰ æœ‰æ¨¡å‹è¡¨ç¾å„ªç•°ï¼å»ºè­°é¸æ“‡F1åˆ†æ•¸æœ€é«˜çš„æ¨¡å‹ã€‚")
            elif results[most_stable_model]['cv_std'] < 0.02:
                st.info("âš–ï¸ æ¨¡å‹ç©©å®šæ€§è‰¯å¥½ï¼Œå»ºè­°é¸æ“‡æœ€ç©©å®šçš„æ¨¡å‹ã€‚")
            else:
                st.warning("âš ï¸ æ¨¡å‹æ€§èƒ½ä¸€èˆ¬ï¼Œå»ºè­°å˜—è©¦ç‰¹å¾µå·¥ç¨‹æˆ–åƒæ•¸èª¿å„ªã€‚")

else:
    st.markdown(f"# {page}")
    st.info("æ­¤é é¢æ­£åœ¨é–‹ç™¼ä¸­ï¼Œæ•¬è«‹æœŸå¾…ï¼")

# æ‡‰ç”¨çµæŸ 